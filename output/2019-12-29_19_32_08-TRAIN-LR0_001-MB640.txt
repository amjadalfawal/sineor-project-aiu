2019-12-29 19:32:08: Embed time: 0.000997304916381836
2019-12-29 19:32:08: Train loss: -103279.36612759416
2019-12-29 19:32:10: Loss time: 0.49268245697021484 Grad time: 1.0721302032470703
2019-12-29 19:32:10: Embed time: 0.0
2019-12-29 19:32:10: Train loss: -103279.54568441026
2019-12-29 19:32:11: Loss time: 0.5395820140838623 Grad time: 1.0870659351348877
2019-12-29 19:32:11: Embed time: 0.000997781753540039
2019-12-29 19:32:12: Train loss: -103279.72728506777
2019-12-29 19:32:13: Loss time: 0.5235998630523682 Grad time: 0.970402717590332
2019-12-29 19:32:13: Embed time: 0.0009975433349609375
2019-12-29 19:32:13: Train loss: -103279.91126880124
2019-12-29 19:32:14: Loss time: 0.7051141262054443 Grad time: 1.0452029705047607
2019-12-29 19:32:14: Embed time: 0.0
2019-12-29 19:32:15: Train loss: -103280.09792088995
2019-12-29 19:32:16: Loss time: 0.5305535793304443 Grad time: 0.9704303741455078
2019-12-29 19:32:16: Embed time: 0.000997304916381836
2019-12-29 19:32:16: Train loss: -103280.2874834968
2019-12-29 19:32:17: Loss time: 0.5375621318817139 Grad time: 0.963423490524292
2019-12-29 19:32:17: Embed time: 0.0
2019-12-29 19:32:18: Train loss: -103280.48018516382
2019-12-29 19:32:19: Loss time: 0.5086369514465332 Grad time: 1.0970656871795654
2019-12-29 19:32:19: Embed time: 0.0009965896606445312
2019-12-29 19:32:20: Train loss: -103280.67625744765
2019-12-29 19:32:21: Loss time: 0.5535180568695068 Grad time: 1.0811071395874023
2019-12-29 19:32:21: Embed time: 0.000997304916381836
2019-12-29 19:32:21: Train loss: -103280.87595403257
2019-12-29 19:32:22: Loss time: 0.5275876522064209 Grad time: 0.9993290901184082
2019-12-29 19:32:22: Embed time: 0.0
2019-12-29 19:32:23: Train loss: -103281.07956048254
2019-12-29 19:32:24: Loss time: 0.5106329917907715 Grad time: 0.9783816337585449
2019-12-29 19:32:25: Validation loss: 1.0 Train loss: -103281.07956048254
2019-12-29 19:32:25: Best model so far (label loss):  1.0 at time 10
2019-12-29 19:32:25: Best model stored at output/models/2019-12-29_19_32_08-TRAIN-LR0_001-MB640.model
2019-12-29 19:32:25: Minibatches processed: 10
2019-12-29 19:32:25: Embed time: 0.0
2019-12-29 19:32:26: Train loss: -103281.28739371734
2019-12-29 19:32:27: Loss time: 0.46475696563720703 Grad time: 1.1265218257904053
2019-12-29 19:32:27: Embed time: 0.000997304916381836
2019-12-29 19:32:27: Train loss: -103281.49979411007
2019-12-29 19:32:28: Loss time: 0.5216042995452881 Grad time: 1.1010525226593018
2019-12-29 19:32:28: Embed time: 0.0
2019-12-29 19:32:29: Train loss: -103281.7171130011
2019-12-29 19:32:30: Loss time: 0.5136256217956543 Grad time: 1.0342333316802979
2019-12-29 19:32:30: Embed time: 0.000997304916381836
2019-12-29 19:32:30: Train loss: -103281.93970268224
2019-12-29 19:32:31: Loss time: 0.5365667343139648 Grad time: 0.9474620819091797
2019-12-29 19:32:31: Embed time: 0.000997304916381836
2019-12-29 19:32:32: Train loss: -103282.16791271105
2019-12-29 19:32:33: Loss time: 0.509638786315918 Grad time: 1.0073049068450928
2019-12-29 19:32:33: Embed time: 0.0009970664978027344
2019-12-29 19:32:33: Train loss: -103282.40209260666
2019-12-29 19:32:34: Loss time: 0.5226013660430908 Grad time: 1.0501883029937744
2019-12-29 19:32:34: Embed time: 0.0
2019-12-29 19:32:35: Train loss: -103282.64259933015
2019-12-29 19:32:36: Loss time: 0.5186138153076172 Grad time: 1.1638844013214111
2019-12-29 19:32:36: Embed time: 0.0009980201721191406
2019-12-29 19:32:37: Train loss: -103282.8898038558
2019-12-29 19:32:38: Loss time: 0.5405542850494385 Grad time: 1.1429407596588135
2019-12-29 19:32:38: Embed time: 0.0009996891021728516
2019-12-29 19:32:38: Train loss: -103283.14409893387
2019-12-29 19:32:40: Loss time: 0.5624945163726807 Grad time: 1.1020514965057373
2019-12-29 19:32:40: Embed time: 0.0
2019-12-29 19:32:40: Train loss: -103283.40590349305
2019-12-29 19:32:41: Loss time: 0.5156199932098389 Grad time: 1.234696626663208
2019-12-29 19:32:43: Validation loss: 1.0 Train loss: -103283.40590349305
2019-12-29 19:32:43: Best model so far (label loss):  1.0 at time 10
2019-12-29 19:32:43: Best model stored at output/models/2019-12-29_19_32_08-TRAIN-LR0_001-MB640.model
2019-12-29 19:32:43: Minibatches processed: 20
2019-12-29 19:32:43: Embed time: 0.0
2019-12-29 19:32:43: Train loss: -103283.67566522954
2019-12-29 19:32:44: Loss time: 0.5545146465301514 Grad time: 1.164881944656372
2019-12-29 19:32:44: Embed time: 0.0009980201721191406
2019-12-29 19:32:45: Train loss: -103283.95386000219
2019-12-29 19:32:46: Loss time: 0.5445451736450195 Grad time: 1.3154778480529785
2019-12-29 19:32:46: Embed time: 0.000997781753540039
2019-12-29 19:32:47: Train loss: -103284.24099061609
2019-12-29 19:32:48: Loss time: 0.5585072040557861 Grad time: 1.0920770168304443
2019-12-29 19:32:48: Embed time: 0.0
2019-12-29 19:32:48: Train loss: -103284.53758301114
2019-12-29 19:32:50: Loss time: 0.5156192779541016 Grad time: 1.1259872913360596
2019-12-29 19:32:50: Embed time: 0.000997781753540039
2019-12-29 19:32:50: Train loss: -103284.84418430268
2019-12-29 19:32:51: Loss time: 0.5425765514373779 Grad time: 1.1967699527740479
2019-12-29 19:32:51: Embed time: 0.0009970664978027344
2019-12-29 19:32:52: Train loss: -103285.161359674
2019-12-29 19:32:53: Loss time: 0.5794496536254883 Grad time: 0.9843652248382568
2019-12-29 19:32:53: Embed time: 0.0
2019-12-29 19:32:53: Train loss: -103285.48969288672
2019-12-29 19:32:54: Loss time: 0.5335748195648193 Grad time: 0.9733941555023193
2019-12-29 19:32:54: Embed time: 0.0009982585906982422
2019-12-29 19:32:55: Train loss: -103285.8297869438
2019-12-29 19:32:56: Loss time: 0.5136253833770752 Grad time: 1.1120233535766602
2019-12-29 19:32:56: Embed time: 0.000997781753540039
2019-12-29 19:32:57: Train loss: -103286.18226540017
2019-12-29 19:32:58: Loss time: 0.5096371173858643 Grad time: 1.1020498275756836
2019-12-29 19:32:58: Embed time: 0.000997304916381836
2019-12-29 19:32:58: Train loss: -103286.54777480544
2019-12-29 19:32:59: Loss time: 0.5176177024841309 Grad time: 0.9903481006622314
2019-12-29 19:33:01: Validation loss: 1.0 Train loss: -103286.54777480544
2019-12-29 19:33:01: Best model so far (label loss):  1.0 at time 10
2019-12-29 19:33:01: Best model stored at output/models/2019-12-29_19_32_08-TRAIN-LR0_001-MB640.model
2019-12-29 19:33:01: Minibatches processed: 30
2019-12-29 19:33:01: Embed time: 0.0009696483612060547
2019-12-29 19:33:01: Train loss: -103286.92698592263
2019-12-29 19:33:02: Loss time: 0.4407920837402344 Grad time: 1.0342347621917725
2019-12-29 19:33:02: Embed time: 0.0
2019-12-29 19:33:03: Train loss: -103287.32059599427
2019-12-29 19:33:04: Loss time: 0.632307767868042 Grad time: 1.2217323780059814
2019-12-29 19:33:04: Embed time: 0.0009982585906982422
2019-12-29 19:33:05: Train loss: -103287.72932892226
2019-12-29 19:33:06: Loss time: 0.5754623413085938 Grad time: 1.1170108318328857
2019-12-29 19:33:06: Embed time: 0.0
2019-12-29 19:33:06: Train loss: -103288.15393669013
2019-12-29 19:33:07: Loss time: 0.5415513515472412 Grad time: 1.1668760776519775
2019-12-29 19:33:07: Embed time: 0.0009965896606445312
2019-12-29 19:33:08: Train loss: -103288.59519918455
2019-12-29 19:33:09: Loss time: 0.5894224643707275 Grad time: 1.2137534618377686
2019-12-29 19:33:09: Embed time: 0.0
2019-12-29 19:33:10: Train loss: -103289.05392276667
2019-12-29 19:33:11: Loss time: 0.5345685482025146 Grad time: 1.1389532089233398
2019-12-29 19:33:11: Embed time: 0.0009970664978027344
2019-12-29 19:33:11: Train loss: -103289.53094046761
2019-12-29 19:33:13: Loss time: 0.5425488948822021 Grad time: 1.14493727684021
2019-12-29 19:33:13: Embed time: 0.0009958744049072266
2019-12-29 19:33:13: Train loss: -103290.02710769449
2019-12-29 19:33:14: Loss time: 0.547544002532959 Grad time: 1.182826280593872
2019-12-29 19:33:14: Embed time: 0.0
2019-12-29 19:33:15: Train loss: -103290.54329958386
2019-12-29 19:33:16: Loss time: 0.523587703704834 Grad time: 1.0282399654388428
2019-12-29 19:33:16: Embed time: 0.0009970664978027344
2019-12-29 19:33:16: Train loss: -103291.08040848773
2019-12-29 19:33:17: Loss time: 0.5385594367980957 Grad time: 1.058168649673462
2019-12-29 19:33:19: Validation loss: 1.0 Train loss: -103291.08040848773
2019-12-29 19:33:19: Best model so far (label loss):  1.0 at time 10
2019-12-29 19:33:19: Best model stored at output/models/2019-12-29_19_32_08-TRAIN-LR0_001-MB640.model
2019-12-29 19:33:19: Minibatches processed: 40
2019-12-29 19:33:19: Embed time: 0.0
2019-12-29 19:33:19: Train loss: -103291.63933616897
2019-12-29 19:33:20: Loss time: 0.5325760841369629 Grad time: 0.9983267784118652
2019-12-29 19:33:20: Embed time: 0.000997781753540039
2019-12-29 19:33:21: Train loss: -103292.22099000809
2019-12-29 19:33:22: Loss time: 0.5325767993927002 Grad time: 0.934499979019165
2019-12-29 19:33:22: Embed time: 0.0
2019-12-29 19:33:22: Train loss: -103292.82627499891
2019-12-29 19:33:23: Loss time: 0.5026569366455078 Grad time: 1.1290054321289062
2019-12-29 19:33:23: Embed time: 0.0
2019-12-29 19:33:24: Train loss: -103293.45608309335
2019-12-29 19:33:25: Loss time: 0.5275881290435791 Grad time: 1.2077703475952148
2019-12-29 19:33:25: Embed time: 0.0009961128234863281
2019-12-29 19:33:26: Train loss: -103294.11128376587
2019-12-29 19:33:27: Loss time: 0.5196082592010498 Grad time: 1.1878232955932617
2019-12-29 19:33:27: Embed time: 0.0009975433349609375
2019-12-29 19:33:27: Train loss: -103294.79270960495
2019-12-29 19:33:28: Loss time: 0.5126287937164307 Grad time: 1.0461993217468262
2019-12-29 19:33:28: Embed time: 0.0
2019-12-29 19:33:29: Train loss: -103295.5011460968
2019-12-29 19:33:30: Loss time: 0.5176150798797607 Grad time: 1.1549103260040283
2019-12-29 19:33:30: Embed time: 0.000997781753540039
2019-12-29 19:33:31: Train loss: -103296.23731758108
2019-12-29 19:33:32: Loss time: 0.5365653038024902 Grad time: 0.9903509616851807
2019-12-29 19:33:32: Embed time: 0.0009975433349609375
2019-12-29 19:33:32: Train loss: -103297.00187348096
2019-12-29 19:33:33: Loss time: 0.5545156002044678 Grad time: 1.0980627536773682
2019-12-29 19:33:33: Embed time: 0.000997304916381836
2019-12-29 19:33:34: Train loss: -103297.79537779788
2019-12-29 19:33:35: Loss time: 0.5156192779541016 Grad time: 1.1499223709106445
2019-12-29 19:33:36: Validation loss: 1.0 Train loss: -103297.79537779788
2019-12-29 19:33:36: Best model so far (label loss):  1.0 at time 10
2019-12-29 19:33:36: Best model stored at output/models/2019-12-29_19_32_08-TRAIN-LR0_001-MB640.model
2019-12-29 19:33:36: Minibatches processed: 50
2019-12-29 19:33:36: Embed time: 0.0
2019-12-29 19:33:37: Train loss: -103298.61829591398
2019-12-29 19:33:38: Loss time: 0.48470306396484375 Grad time: 1.116013526916504
2019-12-29 19:33:38: Embed time: 0.0009968280792236328
2019-12-29 19:33:38: Train loss: -103299.47098248023
2019-12-29 19:33:40: Loss time: 0.5265898704528809 Grad time: 1.1339654922485352
2019-12-29 19:33:40: Embed time: 0.0009989738464355469
2019-12-29 19:33:40: Train loss: -103300.3536688376
2019-12-29 19:33:42: Loss time: 0.5794496536254883 Grad time: 1.3394160270690918
2019-12-29 19:33:42: Embed time: 0.0
2019-12-29 19:33:42: Train loss: -103301.26645813312
2019-12-29 19:33:43: Loss time: 0.5455653667449951 Grad time: 1.2047507762908936
2019-12-29 19:33:43: Embed time: 0.0009961128234863281
2019-12-29 19:33:44: Train loss: -103302.20931285286
2019-12-29 19:33:45: Loss time: 0.5754597187042236 Grad time: 1.1898167133331299
2019-12-29 19:33:45: Embed time: 0.000997304916381836
2019-12-29 19:33:46: Train loss: -103303.18205189395
2019-12-29 19:33:47: Loss time: 0.5355668067932129 Grad time: 1.3364248275756836
2019-12-29 19:33:47: Embed time: 0.0009982585906982422
2019-12-29 19:33:48: Train loss: -103304.18434861836
2019-12-29 19:33:49: Loss time: 0.5435235500335693 Grad time: 1.2725908756256104
2019-12-29 19:33:49: Embed time: 0.000997304916381836
2019-12-29 19:33:49: Train loss: -103305.21572718254
2019-12-29 19:33:50: Loss time: 0.5405533313751221 Grad time: 1.1249897480010986
2019-12-29 19:33:50: Embed time: 0.000997781753540039
2019-12-29 19:33:51: Train loss: -103306.27556764346
2019-12-29 19:33:52: Loss time: 0.5365645885467529 Grad time: 1.262622594833374
2019-12-29 19:33:52: Embed time: 0.0
2019-12-29 19:33:53: Train loss: -103307.36311127775
2019-12-29 19:33:54: Loss time: 0.564490795135498 Grad time: 1.112023115158081
2019-12-29 19:33:55: Validation loss: 1.0 Train loss: -103307.36311127775
2019-12-29 19:33:55: Best model so far (label loss):  1.0 at time 10
2019-12-29 19:33:55: Best model stored at output/models/2019-12-29_19_32_08-TRAIN-LR0_001-MB640.model
2019-12-29 19:33:55: Minibatches processed: 60
2019-12-29 19:33:55: Embed time: 0.0
2019-12-29 19:33:56: Train loss: -103308.47746938239
2019-12-29 19:33:57: Loss time: 0.4936790466308594 Grad time: 1.1778485774993896
2019-12-29 19:33:57: Embed time: 0.0009970664978027344
2019-12-29 19:33:58: Train loss: -103309.61763855966
2019-12-29 19:33:59: Loss time: 0.5824415683746338 Grad time: 1.1419436931610107
2019-12-29 19:33:59: Embed time: 0.000997781753540039
2019-12-29 19:33:59: Train loss: -103310.78251780875
2019-12-29 19:34:01: Loss time: 0.5126285552978516 Grad time: 1.4790434837341309
2019-12-29 19:34:01: Embed time: 0.0009970664978027344
2019-12-29 19:34:01: Train loss: -103311.97092798575
2019-12-29 19:34:03: Loss time: 0.5984008312225342 Grad time: 1.4920070171356201
2019-12-29 19:34:03: Embed time: 0.0009980201721191406
2019-12-29 19:34:03: Train loss: -103313.1816413085
2019-12-29 19:34:05: Loss time: 0.5515267848968506 Grad time: 1.216742753982544
2019-12-29 19:34:05: Embed time: 0.0009968280792236328
2019-12-29 19:34:05: Train loss: -103314.41340587655
2019-12-29 19:34:07: Loss time: 0.5535190105438232 Grad time: 1.2406797409057617
2019-12-29 19:34:07: Embed time: 0.0
2019-12-29 19:34:07: Train loss: -103315.66497037609
2019-12-29 19:34:08: Loss time: 0.5315792560577393 Grad time: 1.122992753982544
2019-12-29 19:34:08: Embed time: 0.0009975433349609375
2019-12-29 19:34:09: Train loss: -103316.93510775821
2019-12-29 19:34:10: Loss time: 0.5066444873809814 Grad time: 1.1279821395874023
2019-12-29 19:34:10: Embed time: 0.0
2019-12-29 19:34:10: Train loss: -103318.22263309095
2019-12-29 19:34:11: Loss time: 0.5425498485565186 Grad time: 0.9494597911834717
2019-12-29 19:34:11: Embed time: 0.0009975433349609375
2019-12-29 19:34:12: Train loss: -103319.52641399454
2019-12-29 19:34:13: Loss time: 0.5046498775482178 Grad time: 0.9873566627502441
2019-12-29 19:34:14: Validation loss: 1.0 Train loss: -103319.52641399454
2019-12-29 19:34:14: Best model so far (label loss):  1.0 at time 10
2019-12-29 19:34:14: Best model stored at output/models/2019-12-29_19_32_08-TRAIN-LR0_001-MB640.model
2019-12-29 19:34:14: Minibatches processed: 70
2019-12-29 19:34:14: Embed time: 0.0
2019-12-29 19:34:15: Train loss: -103320.84538103356
2019-12-29 19:34:16: Loss time: 0.4976675510406494 Grad time: 1.1170134544372559
2019-12-29 19:34:16: Embed time: 0.000997781753540039
2019-12-29 19:34:16: Train loss: -103322.17853294597
2019-12-29 19:34:17: Loss time: 0.5196073055267334 Grad time: 1.110029697418213
2019-12-29 19:34:17: Embed time: 0.0
2019-12-29 19:34:18: Train loss: -103323.52491809645
2019-12-29 19:34:19: Loss time: 0.5206069946289062 Grad time: 1.1489262580871582
2019-12-29 19:34:19: Embed time: 0.0009961128234863281
2019-12-29 19:34:20: Train loss: -103324.88362548794
2019-12-29 19:34:21: Loss time: 0.5136251449584961 Grad time: 1.1160132884979248
2019-12-29 19:34:21: Embed time: 0.001024484634399414
2019-12-29 19:34:21: Train loss: -103326.25377310936
2019-12-29 19:34:22: Loss time: 0.5076415538787842 Grad time: 1.0242605209350586
2019-12-29 19:34:22: Embed time: 0.0009963512420654297
2019-12-29 19:34:23: Train loss: -103327.63448102192
2019-12-29 19:34:24: Loss time: 0.5505259037017822 Grad time: 0.9674382209777832
2019-12-29 19:34:24: Embed time: 0.0009953975677490234
2019-12-29 19:34:24: Train loss: -103329.02486944594
2019-12-29 19:34:26: Loss time: 0.611363410949707 Grad time: 1.1602706909179688
2019-12-29 19:34:26: Embed time: 0.0009987354278564453
2019-12-29 19:34:26: Train loss: -103330.42404175353
2019-12-29 19:34:27: Loss time: 0.5455551147460938 Grad time: 1.2037627696990967
2019-12-29 19:34:27: Embed time: 0.0009963512420654297
2019-12-29 19:34:28: Train loss: -103331.83108067975
2019-12-29 19:34:29: Loss time: 0.559502124786377 Grad time: 1.1698715686798096
2019-12-29 19:34:29: Embed time: 0.0
2019-12-29 19:34:30: Train loss: -103333.24505157475
2019-12-29 19:34:31: Loss time: 0.5385763645172119 Grad time: 1.2885355949401855
2019-12-29 19:34:32: Validation loss: 1.0 Train loss: -103333.24505157475
2019-12-29 19:34:32: Best model so far (label loss):  1.0 at time 10
2019-12-29 19:34:32: Best model stored at output/models/2019-12-29_19_32_08-TRAIN-LR0_001-MB640.model
2019-12-29 19:34:32: Minibatches processed: 80
2019-12-29 19:34:32: Embed time: 0.0009968280792236328
2019-12-29 19:34:33: Train loss: -103334.66501343095
2019-12-29 19:34:34: Loss time: 0.5006613731384277 Grad time: 1.1868228912353516
2019-12-29 19:34:34: Embed time: 0.0009968280792236328
2019-12-29 19:34:35: Train loss: -103336.09002409011
2019-12-29 19:34:36: Loss time: 0.5764570236206055 Grad time: 1.1898155212402344
2019-12-29 19:34:36: Embed time: 0.0
2019-12-29 19:34:36: Train loss: -103337.51916373536
2019-12-29 19:34:37: Loss time: 0.5305993556976318 Grad time: 1.1638669967651367
2019-12-29 19:34:37: Embed time: 0.0009975433349609375
2019-12-29 19:34:38: Train loss: -103338.95155638226
2019-12-29 19:34:39: Loss time: 0.5585062503814697 Grad time: 1.3364241123199463
2019-12-29 19:34:39: Embed time: 0.0009970664978027344
2019-12-29 19:34:40: Train loss: -103340.38639187012
2019-12-29 19:34:41: Loss time: 0.5644900798797607 Grad time: 1.3992562294006348
2019-12-29 19:34:41: Embed time: 0.0009965896606445312
2019-12-29 19:34:42: Train loss: -103341.82293921037
2019-12-29 19:34:43: Loss time: 0.5894217491149902 Grad time: 1.1908135414123535
2019-12-29 19:34:43: Embed time: 0.0009970664978027344
2019-12-29 19:34:44: Train loss: -103343.26055991046
2019-12-29 19:34:45: Loss time: 0.5365653038024902 Grad time: 1.1938059329986572
2019-12-29 19:34:45: Embed time: 0.0
2019-12-29 19:34:45: Train loss: -103344.69872180936
2019-12-29 19:34:47: Loss time: 0.5744631290435791 Grad time: 1.3264517784118652
2019-12-29 19:34:47: Embed time: 0.0009958744049072266
2019-12-29 19:34:47: Train loss: -103346.13699032522
2019-12-29 19:34:48: Loss time: 0.5545144081115723 Grad time: 1.1080353260040283
2019-12-29 19:34:49: Embed time: 0.0
2019-12-29 19:34:49: Train loss: -103347.57503037949
2019-12-29 19:34:50: Loss time: 0.5395650863647461 Grad time: 1.4132106304168701
2019-12-29 19:34:52: Validation loss: 1.0 Train loss: -103347.57503037949
2019-12-29 19:34:52: Best model so far (label loss):  1.0 at time 10
2019-12-29 19:34:52: Best model stored at output/models/2019-12-29_19_32_08-TRAIN-LR0_001-MB640.model
2019-12-29 19:34:52: Minibatches processed: 90
2019-12-29 19:34:52: Embed time: 0.0010294914245605469
2019-12-29 19:34:52: Train loss: -103349.01258696258
2019-12-29 19:34:54: Loss time: 0.5235998630523682 Grad time: 1.1748545169830322
2019-12-29 19:34:54: Embed time: 0.0019943714141845703
2019-12-29 19:34:54: Train loss: -103350.44947712781
2019-12-29 19:34:55: Loss time: 0.53157639503479 Grad time: 1.068143367767334
2019-12-29 19:34:55: Embed time: 0.0
2019-12-29 19:34:56: Train loss: -103351.88557201052
2019-12-29 19:34:57: Loss time: 0.5305540561676025 Grad time: 1.3506810665130615
2019-12-29 19:34:57: Embed time: 0.0
2019-12-29 19:34:58: Train loss: -103353.3207779726
2019-12-29 19:34:59: Loss time: 0.5415501594543457 Grad time: 1.1279826164245605
2019-12-29 19:34:59: Embed time: 0.0
2019-12-29 19:34:59: Train loss: -103354.75501750747
2019-12-29 19:35:01: Loss time: 0.622333288192749 Grad time: 1.2476627826690674
2019-12-29 19:35:01: Embed time: 0.0009968280792236328
2019-12-29 19:35:01: Train loss: -103356.18822421931
2019-12-29 19:35:03: Loss time: 0.5335979461669922 Grad time: 1.3014936447143555
2019-12-29 19:35:03: Embed time: 0.0
2019-12-29 19:35:03: Train loss: -103357.62031671766
2019-12-29 19:35:04: Loss time: 0.5455386638641357 Grad time: 1.2346980571746826
2019-12-29 19:35:04: Embed time: 0.0009975433349609375
2019-12-29 19:35:05: Train loss: -103359.05120301219
2019-12-29 19:35:06: Loss time: 0.5495309829711914 Grad time: 1.1479272842407227
2019-12-29 19:35:06: Embed time: 0.0009989738464355469
2019-12-29 19:35:07: Train loss: -103360.48076505962
2019-12-29 19:35:08: Loss time: 0.607374906539917 Grad time: 1.2147495746612549
2019-12-29 19:35:08: Embed time: 0.000997304916381836
2019-12-29 19:35:08: Train loss: -103361.90886638063
2019-12-29 19:35:10: Loss time: 0.5425477027893066 Grad time: 1.2476654052734375
2019-12-29 19:35:11: Validation loss: 1.0 Train loss: -103361.90886638063
2019-12-29 19:35:11: Best model so far (label loss):  1.0 at time 10
2019-12-29 19:35:11: Best model stored at output/models/2019-12-29_19_32_08-TRAIN-LR0_001-MB640.model
2019-12-29 19:35:11: Minibatches processed: 100
2019-12-29 19:35:11: Embed time: 0.0009975433349609375
2019-12-29 19:35:12: Train loss: -103363.33533658822
2019-12-29 19:35:13: Loss time: 0.5146238803863525 Grad time: 1.2616231441497803
2019-12-29 19:35:13: Embed time: 0.0
2019-12-29 19:35:13: Train loss: -103364.75998588178
2019-12-29 19:35:15: Loss time: 0.5345690250396729 Grad time: 1.1977956295013428
2019-12-29 19:35:15: Embed time: 0.0
2019-12-29 19:35:15: Train loss: -103366.18260295175
2019-12-29 19:35:16: Loss time: 0.5475327968597412 Grad time: 1.1409478187561035
2019-12-29 19:35:16: Embed time: 0.0009963512420654297
2019-12-29 19:35:17: Train loss: -103367.60296123456
2019-12-29 19:35:18: Loss time: 0.5315823554992676 Grad time: 1.5119481086730957
2019-12-29 19:35:18: Embed time: 0.0009968280792236328
2019-12-29 19:35:19: Train loss: -103369.02082549814
2019-12-29 19:35:20: Loss time: 0.559502124786377 Grad time: 1.2247233390808105
2019-12-29 19:35:20: Embed time: 0.0
2019-12-29 19:35:21: Train loss: -103370.435949749
2019-12-29 19:35:22: Loss time: 0.5634913444519043 Grad time: 1.165879487991333
2019-12-29 19:35:22: Embed time: 0.0009980201721191406
2019-12-29 19:35:22: Train loss: -103371.8480875064
2019-12-29 19:35:24: Loss time: 0.5624959468841553 Grad time: 1.1110272407531738
2019-12-29 19:35:24: Embed time: 0.0009999275207519531
2019-12-29 19:35:24: Train loss: -103373.25700424437
2019-12-29 19:35:25: Loss time: 0.5575079917907715 Grad time: 1.2127549648284912
2019-12-29 19:35:25: Embed time: 0.0
2019-12-29 19:35:26: Train loss: -103374.6624700828
2019-12-29 19:35:27: Loss time: 0.5295853614807129 Grad time: 1.0003235340118408
2019-12-29 19:35:27: Embed time: 0.0009989738464355469
2019-12-29 19:35:27: Train loss: -103376.06427287325
2019-12-29 19:35:29: Loss time: 0.5246076583862305 Grad time: 1.0791022777557373
2019-12-29 19:35:30: Validation loss: 1.0 Train loss: -103376.06427287325
2019-12-29 19:35:30: Best model so far (label loss):  1.0 at time 10
2019-12-29 19:35:30: Best model stored at output/models/2019-12-29_19_32_08-TRAIN-LR0_001-MB640.model
2019-12-29 19:35:30: Minibatches processed: 110
