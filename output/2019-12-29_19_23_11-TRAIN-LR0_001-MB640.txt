2019-12-29 19:23:11: Embed time: 0.0009696483612060547
2019-12-29 19:23:12: Train loss: -103279.36612759416
2019-12-29 19:23:13: Loss time: 0.44577860832214355 Grad time: 1.195796251296997
2019-12-29 19:23:13: Embed time: 0.00099945068359375
2019-12-29 19:23:13: Train loss: -103279.54568441026
2019-12-29 19:23:15: Loss time: 0.5944101810455322 Grad time: 1.2416775226593018
2019-12-29 19:23:15: Embed time: 0.0009970664978027344
2019-12-29 19:23:15: Train loss: -103279.72728506777
2019-12-29 19:23:16: Loss time: 0.5256192684173584 Grad time: 1.1020245552062988
2019-12-29 19:23:16: Embed time: 0.000997304916381836
2019-12-29 19:23:17: Train loss: -103279.91126880124
2019-12-29 19:23:18: Loss time: 0.5505270957946777 Grad time: 1.116013526916504
2019-12-29 19:23:18: Embed time: 0.0009970664978027344
2019-12-29 19:23:18: Train loss: -103280.09792088995
2019-12-29 19:23:20: Loss time: 0.527590274810791 Grad time: 1.2925400733947754
2019-12-29 19:23:20: Embed time: 0.0009992122650146484
2019-12-29 19:23:20: Train loss: -103280.2874834968
2019-12-29 19:23:21: Loss time: 0.5465643405914307 Grad time: 1.126861333847046
2019-12-29 19:23:21: Embed time: 0.0009970664978027344
2019-12-29 19:23:22: Train loss: -103280.48018516382
2019-12-29 19:23:23: Loss time: 0.5614969730377197 Grad time: 1.1648828983306885
2019-12-29 19:23:23: Embed time: 0.0
2019-12-29 19:23:24: Train loss: -103280.67625744765
2019-12-29 19:23:25: Loss time: 0.5385587215423584 Grad time: 1.0801112651824951
2019-12-29 19:23:25: Embed time: 0.0
2019-12-29 19:23:25: Train loss: -103280.87595403257
2019-12-29 19:23:27: Loss time: 0.5365638732910156 Grad time: 1.2037770748138428
2019-12-29 19:23:27: Embed time: 0.0009968280792236328
2019-12-29 19:23:27: Train loss: -103281.07956048254
2019-12-29 19:23:28: Loss time: 0.5295851230621338 Grad time: 1.025254726409912
2019-12-29 19:23:30: Validation loss: 1.0 Train loss: -103281.07956048254
2019-12-29 19:23:30: Best model so far (label loss):  1.0 at time 10
2019-12-29 19:23:30: Best model stored at output/models/2019-12-29_19_23_11-TRAIN-LR0_001-MB640.model
2019-12-29 19:23:30: Minibatches processed: 10
2019-12-29 19:23:30: Embed time: 0.000997304916381836
2019-12-29 19:23:30: Train loss: -103281.28739371734
2019-12-29 19:23:31: Loss time: 0.5435450077056885 Grad time: 1.1180086135864258
2019-12-29 19:23:31: Embed time: 0.0009965896606445312
2019-12-29 19:23:32: Train loss: -103281.49979411007
2019-12-29 19:23:33: Loss time: 0.5285847187042236 Grad time: 0.9863605499267578
2019-12-29 19:23:33: Embed time: 0.0
2019-12-29 19:23:33: Train loss: -103281.7171130011
2019-12-29 19:23:34: Loss time: 0.5265898704528809 Grad time: 1.1219983100891113
2019-12-29 19:23:34: Embed time: 0.000997781753540039
2019-12-29 19:23:35: Train loss: -103281.93970268224
2019-12-29 19:23:36: Loss time: 0.52559494972229 Grad time: 1.2167432308197021
2019-12-29 19:23:36: Embed time: 0.0009970664978027344
2019-12-29 19:23:37: Train loss: -103282.16791271105
2019-12-29 19:23:38: Loss time: 0.5614960193634033 Grad time: 1.1200025081634521
2019-12-29 19:23:38: Embed time: 0.0
2019-12-29 19:23:38: Train loss: -103282.40209260666
2019-12-29 19:23:40: Loss time: 0.5525209903717041 Grad time: 1.188819169998169
2019-12-29 19:23:40: Embed time: 0.0
2019-12-29 19:23:40: Train loss: -103282.64259933015
2019-12-29 19:23:41: Loss time: 0.5784540176391602 Grad time: 1.2177400588989258
2019-12-29 19:23:41: Embed time: 0.0
2019-12-29 19:23:42: Train loss: -103282.8898038558
2019-12-29 19:23:43: Loss time: 0.5335726737976074 Grad time: 1.282567024230957
2019-12-29 19:23:43: Embed time: 0.0009970664978027344
2019-12-29 19:23:44: Train loss: -103283.14409893387
2019-12-29 19:23:45: Loss time: 0.5674803256988525 Grad time: 1.0691399574279785
2019-12-29 19:23:45: Embed time: 0.0
2019-12-29 19:23:45: Train loss: -103283.40590349305
2019-12-29 19:23:46: Loss time: 0.5305788516998291 Grad time: 1.0920782089233398
2019-12-29 19:23:48: Validation loss: 1.0 Train loss: -103283.40590349305
2019-12-29 19:23:48: Best model so far (label loss):  1.0 at time 10
2019-12-29 19:23:48: Best model stored at output/models/2019-12-29_19_23_11-TRAIN-LR0_001-MB640.model
2019-12-29 19:23:48: Minibatches processed: 20
2019-12-29 19:23:48: Embed time: 0.000997781753540039
2019-12-29 19:23:48: Train loss: -103283.67566522954
2019-12-29 19:23:49: Loss time: 0.500659704208374 Grad time: 1.0810813903808594
2019-12-29 19:23:49: Embed time: 0.000997304916381836
2019-12-29 19:23:50: Train loss: -103283.95386000219
2019-12-29 19:23:51: Loss time: 0.5166158676147461 Grad time: 0.9364938735961914
2019-12-29 19:23:51: Embed time: 0.0009968280792236328
2019-12-29 19:23:51: Train loss: -103284.24099061609
2019-12-29 19:23:52: Loss time: 0.5156183242797852 Grad time: 1.063157558441162
2019-12-29 19:23:52: Embed time: 0.0009970664978027344
2019-12-29 19:23:53: Train loss: -103284.53758301114
2019-12-29 19:23:54: Loss time: 0.5295863151550293 Grad time: 1.1180059909820557
2019-12-29 19:23:54: Embed time: 0.0009982585906982422
2019-12-29 19:23:55: Train loss: -103284.84418430268
2019-12-29 19:23:56: Loss time: 0.5465373992919922 Grad time: 1.111027479171753
2019-12-29 19:23:56: Embed time: 0.000997304916381836
2019-12-29 19:23:56: Train loss: -103285.161359674
2019-12-29 19:23:58: Loss time: 0.5515227317810059 Grad time: 1.2765846252441406
2019-12-29 19:23:58: Embed time: 0.000997781753540039
2019-12-29 19:23:58: Train loss: -103285.48969288672
2019-12-29 19:23:59: Loss time: 0.5186142921447754 Grad time: 1.120004653930664
2019-12-29 19:23:59: Embed time: 0.0010228157043457031
2019-12-29 19:24:00: Train loss: -103285.8297869438
2019-12-29 19:24:01: Loss time: 0.6133584976196289 Grad time: 1.14693284034729
2019-12-29 19:24:01: Embed time: 0.0009982585906982422
2019-12-29 19:24:02: Train loss: -103286.18226540017
2019-12-29 19:24:03: Loss time: 0.5226001739501953 Grad time: 1.184830665588379
2019-12-29 19:24:03: Embed time: 0.0009992122650146484
2019-12-29 19:24:03: Train loss: -103286.54777480544
2019-12-29 19:24:05: Loss time: 0.5964055061340332 Grad time: 1.2137527465820312
2019-12-29 19:24:06: Validation loss: 1.0 Train loss: -103286.54777480544
2019-12-29 19:24:06: Best model so far (label loss):  1.0 at time 10
2019-12-29 19:24:06: Best model stored at output/models/2019-12-29_19_23_11-TRAIN-LR0_001-MB640.model
2019-12-29 19:24:06: Minibatches processed: 30
2019-12-29 19:24:06: Embed time: 0.0
2019-12-29 19:24:06: Train loss: -103286.92698592263
2019-12-29 19:24:07: Loss time: 0.4886622428894043 Grad time: 0.95444655418396
2019-12-29 19:24:07: Embed time: 0.0
2019-12-29 19:24:08: Train loss: -103287.32059599427
2019-12-29 19:24:09: Loss time: 0.5555126667022705 Grad time: 1.1848297119140625
2019-12-29 19:24:09: Embed time: 0.000997304916381836
2019-12-29 19:24:10: Train loss: -103287.72932892226
2019-12-29 19:24:11: Loss time: 0.5226030349731445 Grad time: 1.1030473709106445
2019-12-29 19:24:11: Embed time: 0.0009970664978027344
2019-12-29 19:24:11: Train loss: -103288.15393669013
2019-12-29 19:24:12: Loss time: 0.5634913444519043 Grad time: 1.0711336135864258
2019-12-29 19:24:12: Embed time: 0.000997304916381836
2019-12-29 19:24:13: Train loss: -103288.59519918455
2019-12-29 19:24:14: Loss time: 0.5515241622924805 Grad time: 1.1828346252441406
2019-12-29 19:24:14: Embed time: 0.0
2019-12-29 19:24:15: Train loss: -103289.05392276667
2019-12-29 19:24:16: Loss time: 0.5176172256469727 Grad time: 1.0013189315795898
2019-12-29 19:24:16: Embed time: 0.0
2019-12-29 19:24:16: Train loss: -103289.53094046761
2019-12-29 19:24:17: Loss time: 0.5305817127227783 Grad time: 1.0821306705474854
2019-12-29 19:24:17: Embed time: 0.0
2019-12-29 19:24:18: Train loss: -103290.02710769449
2019-12-29 19:24:19: Loss time: 0.5515239238739014 Grad time: 1.029245138168335
2019-12-29 19:24:19: Embed time: 0.0
2019-12-29 19:24:19: Train loss: -103290.54329958386
2019-12-29 19:24:20: Loss time: 0.5924324989318848 Grad time: 1.0322191715240479
2019-12-29 19:24:20: Embed time: 0.0009970664978027344
2019-12-29 19:24:21: Train loss: -103291.08040848773
2019-12-29 19:24:22: Loss time: 0.5305814743041992 Grad time: 0.9733941555023193
2019-12-29 19:24:23: Validation loss: 1.0 Train loss: -103291.08040848773
2019-12-29 19:24:23: Best model so far (label loss):  1.0 at time 10
2019-12-29 19:24:23: Best model stored at output/models/2019-12-29_19_23_11-TRAIN-LR0_001-MB640.model
2019-12-29 19:24:23: Minibatches processed: 40
2019-12-29 19:24:23: Embed time: 0.0009801387786865234
2019-12-29 19:24:24: Train loss: -103291.63933616897
2019-12-29 19:24:25: Loss time: 0.4657320976257324 Grad time: 1.1638867855072021
2019-12-29 19:24:25: Embed time: 0.000997304916381836
2019-12-29 19:24:25: Train loss: -103292.22099000809
2019-12-29 19:24:26: Loss time: 0.5734655857086182 Grad time: 0.9923455715179443
2019-12-29 19:24:26: Embed time: 0.0009975433349609375
2019-12-29 19:24:27: Train loss: -103292.82627499891
2019-12-29 19:24:28: Loss time: 0.5275886058807373 Grad time: 1.0531816482543945
2019-12-29 19:24:28: Embed time: 0.0009975433349609375
2019-12-29 19:24:29: Train loss: -103293.45608309335
2019-12-29 19:24:30: Loss time: 0.5226006507873535 Grad time: 1.0083181858062744
2019-12-29 19:24:30: Embed time: 0.0009970664978027344
2019-12-29 19:24:30: Train loss: -103294.11128376587
2019-12-29 19:24:31: Loss time: 0.6193428039550781 Grad time: 1.156905174255371
2019-12-29 19:24:31: Embed time: 0.0009968280792236328
2019-12-29 19:24:32: Train loss: -103294.79270960495
2019-12-29 19:24:33: Loss time: 0.5245959758758545 Grad time: 1.0432095527648926
2019-12-29 19:24:33: Embed time: 0.0009970664978027344
2019-12-29 19:24:33: Train loss: -103295.5011460968
2019-12-29 19:24:35: Loss time: 0.5405304431915283 Grad time: 1.0890834331512451
2019-12-29 19:24:35: Embed time: 0.000997304916381836
2019-12-29 19:24:35: Train loss: -103296.23731758108
2019-12-29 19:24:36: Loss time: 0.5146229267120361 Grad time: 1.259629726409912
2019-12-29 19:24:36: Embed time: 0.0009970664978027344
2019-12-29 19:24:37: Train loss: -103297.00187348096
2019-12-29 19:24:38: Loss time: 0.5425457954406738 Grad time: 1.224724531173706
2019-12-29 19:24:38: Embed time: 0.0009968280792236328
2019-12-29 19:24:39: Train loss: -103297.79537779788
2019-12-29 19:24:40: Loss time: 0.5455396175384521 Grad time: 1.0920767784118652
2019-12-29 19:24:41: Validation loss: 1.0 Train loss: -103297.79537779788
2019-12-29 19:24:41: Best model so far (label loss):  1.0 at time 10
2019-12-29 19:24:41: Best model stored at output/models/2019-12-29_19_23_11-TRAIN-LR0_001-MB640.model
2019-12-29 19:24:41: Minibatches processed: 50
2019-12-29 19:24:41: Embed time: 0.000997781753540039
2019-12-29 19:24:42: Train loss: -103298.61829591398
2019-12-29 19:24:43: Loss time: 0.4747292995452881 Grad time: 1.1469309329986572
2019-12-29 19:24:43: Embed time: 0.000997781753540039
2019-12-29 19:24:43: Train loss: -103299.47098248023
2019-12-29 19:24:44: Loss time: 0.5255947113037109 Grad time: 1.026252031326294
2019-12-29 19:24:44: Embed time: 0.000997781753540039
2019-12-29 19:24:45: Train loss: -103300.3536688376
