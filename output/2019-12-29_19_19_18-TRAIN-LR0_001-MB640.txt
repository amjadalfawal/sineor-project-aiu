2019-12-29 19:19:18: Embed time: 0.0009703636169433594
2019-12-29 19:19:19: Train loss: -103279.36612759416
2019-12-29 19:19:20: Loss time: 0.48667001724243164 Grad time: 1.14393949508667
2019-12-29 19:19:20: Embed time: 0.000997304916381836
2019-12-29 19:19:21: Train loss: -103279.54568441026
2019-12-29 19:19:22: Loss time: 0.5196101665496826 Grad time: 1.0681438446044922
2019-12-29 19:19:22: Embed time: 0.0
2019-12-29 19:19:22: Train loss: -103279.72728506777
2019-12-29 19:19:23: Loss time: 0.5305781364440918 Grad time: 1.0910825729370117
2019-12-29 19:19:23: Embed time: 0.0009975433349609375
2019-12-29 19:19:24: Train loss: -103279.91126880124
2019-12-29 19:19:25: Loss time: 0.5465130805969238 Grad time: 1.0821025371551514
2019-12-29 19:19:25: Embed time: 0.0009965896606445312
2019-12-29 19:19:25: Train loss: -103280.09792088995
2019-12-29 19:19:27: Loss time: 0.5335733890533447 Grad time: 1.4162094593048096
2019-12-29 19:19:27: Embed time: 0.000997781753540039
2019-12-29 19:19:27: Train loss: -103280.2874834968
2019-12-29 19:19:29: Loss time: 0.5724697113037109 Grad time: 1.1180074214935303
2019-12-29 19:19:29: Embed time: 0.000997781753540039
2019-12-29 19:19:29: Train loss: -103280.48018516382
2019-12-29 19:19:30: Loss time: 0.612360954284668 Grad time: 1.0801115036010742
2019-12-29 19:19:30: Embed time: 0.000997304916381836
2019-12-29 19:19:31: Train loss: -103280.67625744765
2019-12-29 19:19:32: Loss time: 0.5634942054748535 Grad time: 1.0452024936676025
2019-12-29 19:19:32: Embed time: 0.000997781753540039
2019-12-29 19:19:32: Train loss: -103280.87595403257
2019-12-29 19:19:34: Loss time: 0.5565106868743896 Grad time: 1.173858404159546
2019-12-29 19:19:34: Embed time: 0.000997781753540039
2019-12-29 19:19:34: Train loss: -103281.07956048254
2019-12-29 19:19:35: Loss time: 0.5804495811462402 Grad time: 1.172861099243164
2019-12-29 19:19:37: Validation loss: 1.0 Train loss: -103281.07956048254
2019-12-29 19:19:37: Best model so far (label loss):  1.0 at time 10
2019-12-29 19:19:37: Best model stored at output/models/2019-12-29_19_19_18-TRAIN-LR0_001-MB640.model
2019-12-29 19:19:37: Minibatches processed: 10
2019-12-29 19:19:37: Embed time: 0.0
2019-12-29 19:19:37: Train loss: -103281.28739371734
2019-12-29 19:19:38: Loss time: 0.5395553112030029 Grad time: 1.2007865905761719
2019-12-29 19:19:39: Embed time: 0.0
2019-12-29 19:19:39: Train loss: -103281.49979411007
2019-12-29 19:19:40: Loss time: 0.529583215713501 Grad time: 1.0342590808868408
2019-12-29 19:19:40: Embed time: 0.0
2019-12-29 19:19:41: Train loss: -103281.7171130011
2019-12-29 19:19:42: Loss time: 0.5345504283905029 Grad time: 1.0452032089233398
2019-12-29 19:19:42: Embed time: 0.0
2019-12-29 19:19:42: Train loss: -103281.93970268224
2019-12-29 19:19:43: Loss time: 0.5555140972137451 Grad time: 1.1957998275756836
2019-12-29 19:19:43: Embed time: 0.0009970664978027344
2019-12-29 19:19:44: Train loss: -103282.16791271105
2019-12-29 19:19:45: Loss time: 0.5265922546386719 Grad time: 1.060161828994751
2019-12-29 19:19:45: Embed time: 0.0
2019-12-29 19:19:46: Train loss: -103282.40209260666
2019-12-29 19:19:47: Loss time: 0.5235989093780518 Grad time: 1.0551786422729492
2019-12-29 19:19:47: Embed time: 0.0009980201721191406
2019-12-29 19:19:47: Train loss: -103282.64259933015
2019-12-29 19:19:48: Loss time: 0.509636640548706 Grad time: 1.0541796684265137
2019-12-29 19:19:48: Embed time: 0.0009975433349609375
2019-12-29 19:19:49: Train loss: -103282.8898038558
2019-12-29 19:19:50: Loss time: 0.5475368499755859 Grad time: 1.1918089389801025
2019-12-29 19:19:50: Embed time: 0.0019936561584472656
2019-12-29 19:19:50: Train loss: -103283.14409893387
2019-12-29 19:19:52: Loss time: 0.5266010761260986 Grad time: 1.0860846042633057
2019-12-29 19:19:52: Embed time: 0.0
2019-12-29 19:19:52: Train loss: -103283.40590349305
2019-12-29 19:19:53: Loss time: 0.5086383819580078 Grad time: 0.9833683967590332
2019-12-29 19:19:54: Validation loss: 1.0 Train loss: -103283.40590349305
2019-12-29 19:19:54: Best model so far (label loss):  1.0 at time 10
2019-12-29 19:19:54: Best model stored at output/models/2019-12-29_19_19_18-TRAIN-LR0_001-MB640.model
2019-12-29 19:19:54: Minibatches processed: 20
2019-12-29 19:19:54: Embed time: 0.000997304916381836
2019-12-29 19:19:55: Train loss: -103283.67566522954
2019-12-29 19:19:56: Loss time: 0.45677757263183594 Grad time: 1.0232598781585693
2019-12-29 19:19:56: Embed time: 0.0009975433349609375
2019-12-29 19:19:56: Train loss: -103283.95386000219
2019-12-29 19:19:57: Loss time: 0.5126292705535889 Grad time: 0.9584610462188721
2019-12-29 19:19:57: Embed time: 0.000997304916381836
2019-12-29 19:19:58: Train loss: -103284.24099061609
2019-12-29 19:19:59: Loss time: 0.5186104774475098 Grad time: 1.0362281799316406
2019-12-29 19:19:59: Embed time: 0.0009982585906982422
2019-12-29 19:19:59: Train loss: -103284.53758301114
2019-12-29 19:20:00: Loss time: 0.5335750579833984 Grad time: 0.9723975658416748
2019-12-29 19:20:00: Embed time: 0.000997304916381836
2019-12-29 19:20:01: Train loss: -103284.84418430268
2019-12-29 19:20:02: Loss time: 0.5046513080596924 Grad time: 0.9255216121673584
2019-12-29 19:20:02: Embed time: 0.0010039806365966797
2019-12-29 19:20:02: Train loss: -103285.161359674
2019-12-29 19:20:03: Loss time: 0.5066184997558594 Grad time: 0.8966288566589355
2019-12-29 19:20:03: Embed time: 0.000997304916381836
2019-12-29 19:20:04: Train loss: -103285.48969288672
2019-12-29 19:20:05: Loss time: 0.5196089744567871 Grad time: 1.0880906581878662
2019-12-29 19:20:05: Embed time: 0.0
2019-12-29 19:20:05: Train loss: -103285.8297869438
2019-12-29 19:20:06: Loss time: 0.5196113586425781 Grad time: 1.0212650299072266
2019-12-29 19:20:06: Embed time: 0.000997304916381836
2019-12-29 19:20:07: Train loss: -103286.18226540017
2019-12-29 19:20:08: Loss time: 0.5205802917480469 Grad time: 0.9783825874328613
2019-12-29 19:20:08: Embed time: 0.0009968280792236328
2019-12-29 19:20:08: Train loss: -103286.54777480544
2019-12-29 19:20:10: Loss time: 0.5076148509979248 Grad time: 1.043210506439209
2019-12-29 19:20:11: Validation loss: 1.0 Train loss: -103286.54777480544
2019-12-29 19:20:11: Best model so far (label loss):  1.0 at time 10
2019-12-29 19:20:11: Best model stored at output/models/2019-12-29_19_19_18-TRAIN-LR0_001-MB640.model
2019-12-29 19:20:11: Minibatches processed: 30
2019-12-29 19:20:11: Embed time: 0.0
2019-12-29 19:20:11: Train loss: -103286.92698592263
2019-12-29 19:20:12: Loss time: 0.5096371173858643 Grad time: 1.0053081512451172
2019-12-29 19:20:12: Embed time: 0.0
2019-12-29 19:20:13: Train loss: -103287.32059599427
2019-12-29 19:20:14: Loss time: 0.5186128616333008 Grad time: 1.0063083171844482
2019-12-29 19:20:14: Embed time: 0.0009980201721191406
2019-12-29 19:20:14: Train loss: -103287.72932892226
2019-12-29 19:20:16: Loss time: 0.5236008167266846 Grad time: 1.0831007957458496
2019-12-29 19:20:16: Embed time: 0.000997781753540039
2019-12-29 19:20:16: Train loss: -103288.15393669013
2019-12-29 19:20:17: Loss time: 0.5196356773376465 Grad time: 1.0631294250488281
2019-12-29 19:20:17: Embed time: 0.0009975433349609375
2019-12-29 19:20:18: Train loss: -103288.59519918455
2019-12-29 19:20:19: Loss time: 0.5884253978729248 Grad time: 1.2406814098358154
2019-12-29 19:20:19: Embed time: 0.000997304916381836
2019-12-29 19:20:20: Train loss: -103289.05392276667
2019-12-29 19:20:21: Loss time: 0.5375618934631348 Grad time: 1.151918649673462
2019-12-29 19:20:21: Embed time: 0.0
2019-12-29 19:20:21: Train loss: -103289.53094046761
2019-12-29 19:20:22: Loss time: 0.5375609397888184 Grad time: 0.9694058895111084
2019-12-29 19:20:22: Embed time: 0.000997781753540039
2019-12-29 19:20:23: Train loss: -103290.02710769449
2019-12-29 19:20:24: Loss time: 0.5216054916381836 Grad time: 1.0920791625976562
2019-12-29 19:20:24: Embed time: 0.0009963512420654297
2019-12-29 19:20:24: Train loss: -103290.54329958386
2019-12-29 19:20:25: Loss time: 0.5275874137878418 Grad time: 0.9544460773468018
2019-12-29 19:20:25: Embed time: 0.0009968280792236328
2019-12-29 19:20:26: Train loss: -103291.08040848773
2019-12-29 19:20:27: Loss time: 0.5196096897125244 Grad time: 1.1658806800842285
2019-12-29 19:20:28: Validation loss: 1.0 Train loss: -103291.08040848773
2019-12-29 19:20:28: Best model so far (label loss):  1.0 at time 10
2019-12-29 19:20:28: Best model stored at output/models/2019-12-29_19_19_18-TRAIN-LR0_001-MB640.model
2019-12-29 19:20:28: Minibatches processed: 40
2019-12-29 19:20:28: Embed time: 0.0009946823120117188
2019-12-29 19:20:29: Train loss: -103291.63933616897
2019-12-29 19:20:30: Loss time: 0.5146193504333496 Grad time: 1.2047765254974365
2019-12-29 19:20:30: Embed time: 0.000997304916381836
2019-12-29 19:20:31: Train loss: -103292.22099000809
2019-12-29 19:20:32: Loss time: 0.539557933807373 Grad time: 1.1678743362426758
2019-12-29 19:20:32: Embed time: 0.0009975433349609375
2019-12-29 19:20:32: Train loss: -103292.82627499891
2019-12-29 19:20:34: Loss time: 0.5415537357330322 Grad time: 1.2187371253967285
2019-12-29 19:20:34: Embed time: 0.0
2019-12-29 19:20:34: Train loss: -103293.45608309335
2019-12-29 19:20:35: Loss time: 0.5435459613800049 Grad time: 1.0900828838348389
2019-12-29 19:20:35: Embed time: 0.000997304916381836
2019-12-29 19:20:36: Train loss: -103294.11128376587
2019-12-29 19:20:37: Loss time: 0.5415496826171875 Grad time: 1.3045220375061035
2019-12-29 19:20:37: Embed time: 0.0
2019-12-29 19:20:38: Train loss: -103294.79270960495
2019-12-29 19:20:39: Loss time: 0.5605001449584961 Grad time: 1.1848299503326416
2019-12-29 19:20:39: Embed time: 0.0
2019-12-29 19:20:39: Train loss: -103295.5011460968
2019-12-29 19:20:40: Loss time: 0.5335714817047119 Grad time: 0.9345016479492188
2019-12-29 19:20:40: Embed time: 0.0009958744049072266
2019-12-29 19:20:41: Train loss: -103296.23731758108
2019-12-29 19:20:42: Loss time: 0.5265908241271973 Grad time: 1.198791742324829
2019-12-29 19:20:42: Embed time: 0.0
2019-12-29 19:20:43: Train loss: -103297.00187348096
2019-12-29 19:20:44: Loss time: 0.5575103759765625 Grad time: 1.2676067352294922
2019-12-29 19:20:44: Embed time: 0.000997781753540039
2019-12-29 19:20:44: Train loss: -103297.79537779788
2019-12-29 19:20:46: Loss time: 0.526592493057251 Grad time: 1.1708660125732422
2019-12-29 19:20:47: Validation loss: 1.0 Train loss: -103297.79537779788
2019-12-29 19:20:47: Best model so far (label loss):  1.0 at time 10
2019-12-29 19:20:47: Best model stored at output/models/2019-12-29_19_19_18-TRAIN-LR0_001-MB640.model
2019-12-29 19:20:47: Minibatches processed: 50
2019-12-29 19:20:47: Embed time: 0.0009951591491699219
2019-12-29 19:20:47: Train loss: -103298.61829591398
2019-12-29 19:20:49: Loss time: 0.4996609687805176 Grad time: 1.286557912826538
2019-12-29 19:20:49: Embed time: 0.0
2019-12-29 19:20:49: Train loss: -103299.47098248023
2019-12-29 19:20:50: Loss time: 0.5555121898651123 Grad time: 1.0452039241790771
2019-12-29 19:20:50: Embed time: 0.000997304916381836
2019-12-29 19:20:51: Train loss: -103300.3536688376
2019-12-29 19:20:52: Loss time: 0.5465378761291504 Grad time: 1.2376880645751953
2019-12-29 19:20:52: Embed time: 0.000997304916381836
2019-12-29 19:20:53: Train loss: -103301.26645813312
2019-12-29 19:20:54: Loss time: 0.5754604339599609 Grad time: 1.2227287292480469
2019-12-29 19:20:54: Embed time: 0.0
2019-12-29 19:20:55: Train loss: -103302.20931285286
2019-12-29 19:20:56: Loss time: 0.5285859107971191 Grad time: 1.1379544734954834
2019-12-29 19:20:56: Embed time: 0.0009970664978027344
2019-12-29 19:20:56: Train loss: -103303.18205189395
2019-12-29 19:20:57: Loss time: 0.5365920066833496 Grad time: 0.9813473224639893
2019-12-29 19:20:57: Embed time: 0.0
2019-12-29 19:20:58: Train loss: -103304.18434861836
2019-12-29 19:20:59: Loss time: 0.5226027965545654 Grad time: 0.965416669845581
2019-12-29 19:20:59: Embed time: 0.0
2019-12-29 19:20:59: Train loss: -103305.21572718254
2019-12-29 19:21:00: Loss time: 0.5614972114562988 Grad time: 1.0631542205810547
2019-12-29 19:21:00: Embed time: 0.0
2019-12-29 19:21:01: Train loss: -103306.27556764346
2019-12-29 19:21:02: Loss time: 0.5245964527130127 Grad time: 1.0192747116088867
2019-12-29 19:21:02: Embed time: 0.0
2019-12-29 19:21:02: Train loss: -103307.36311127775
2019-12-29 19:21:03: Loss time: 0.5186121463775635 Grad time: 1.0860941410064697
2019-12-29 19:21:05: Validation loss: 1.0 Train loss: -103307.36311127775
2019-12-29 19:21:05: Best model so far (label loss):  1.0 at time 10
2019-12-29 19:21:05: Best model stored at output/models/2019-12-29_19_19_18-TRAIN-LR0_001-MB640.model
2019-12-29 19:21:05: Minibatches processed: 60
2019-12-29 19:21:05: Embed time: 0.0
2019-12-29 19:21:05: Train loss: -103308.47746938239
2019-12-29 19:21:06: Loss time: 0.4796931743621826 Grad time: 1.0701372623443604
2019-12-29 19:21:06: Embed time: 0.0009975433349609375
2019-12-29 19:21:07: Train loss: -103309.61763855966
2019-12-29 19:21:08: Loss time: 0.5166170597076416 Grad time: 0.9614274501800537
2019-12-29 19:21:08: Embed time: 0.0
2019-12-29 19:21:08: Train loss: -103310.78251780875
2019-12-29 19:21:10: Loss time: 0.5355677604675293 Grad time: 1.2207329273223877
2019-12-29 19:21:10: Embed time: 0.0009984970092773438
2019-12-29 19:21:10: Train loss: -103311.97092798575
2019-12-29 19:21:11: Loss time: 0.553518533706665 Grad time: 1.0422117710113525
2019-12-29 19:21:11: Embed time: 0.0
2019-12-29 19:21:12: Train loss: -103313.1816413085
2019-12-29 19:21:13: Loss time: 0.5365641117095947 Grad time: 1.2307078838348389
2019-12-29 19:21:13: Embed time: 0.000997781753540039
2019-12-29 19:21:14: Train loss: -103314.41340587655
2019-12-29 19:21:15: Loss time: 0.5395560264587402 Grad time: 0.9923450946807861
2019-12-29 19:21:15: Embed time: 0.0009970664978027344
2019-12-29 19:21:15: Train loss: -103315.66497037609
2019-12-29 19:21:16: Loss time: 0.584435224533081 Grad time: 1.303513526916504
2019-12-29 19:21:16: Embed time: 0.0
2019-12-29 19:21:17: Train loss: -103316.93510775821
2019-12-29 19:21:18: Loss time: 0.5804474353790283 Grad time: 1.05417799949646
2019-12-29 19:21:18: Embed time: 0.0009968280792236328
2019-12-29 19:21:19: Train loss: -103318.22263309095
2019-12-29 19:21:20: Loss time: 0.5385584831237793 Grad time: 1.1269853115081787
2019-12-29 19:21:20: Embed time: 0.0009968280792236328
2019-12-29 19:21:20: Train loss: -103319.52641399454
2019-12-29 19:21:21: Loss time: 0.5425498485565186 Grad time: 1.1788434982299805
2019-12-29 19:21:23: Validation loss: 1.0 Train loss: -103319.52641399454
2019-12-29 19:21:23: Best model so far (label loss):  1.0 at time 10
2019-12-29 19:21:23: Best model stored at output/models/2019-12-29_19_19_18-TRAIN-LR0_001-MB640.model
2019-12-29 19:21:23: Minibatches processed: 70
2019-12-29 19:21:23: Embed time: 0.0
2019-12-29 19:21:23: Train loss: -103320.84538103356
2019-12-29 19:21:25: Loss time: 0.49866819381713867 Grad time: 1.139949083328247
2019-12-29 19:21:25: Embed time: 0.0
2019-12-29 19:21:25: Train loss: -103322.17853294597
2019-12-29 19:21:26: Loss time: 0.5814428329467773 Grad time: 1.3294422626495361
2019-12-29 19:21:26: Embed time: 0.000997304916381836
2019-12-29 19:21:27: Train loss: -103323.52491809645
2019-12-29 19:21:28: Loss time: 0.5515499114990234 Grad time: 1.2177155017852783
2019-12-29 19:21:28: Embed time: 0.0
2019-12-29 19:21:29: Train loss: -103324.88362548794
2019-12-29 19:21:30: Loss time: 0.5505263805389404 Grad time: 1.1299769878387451
2019-12-29 19:21:30: Embed time: 0.0
2019-12-29 19:21:30: Train loss: -103326.25377310936
2019-12-29 19:21:32: Loss time: 0.5325751304626465 Grad time: 1.2855608463287354
2019-12-29 19:21:32: Embed time: 0.0
2019-12-29 19:21:32: Train loss: -103327.63448102192
2019-12-29 19:21:34: Loss time: 0.5415592193603516 Grad time: 1.2685987949371338
2019-12-29 19:21:34: Embed time: 0.0009980201721191406
2019-12-29 19:21:34: Train loss: -103329.02486944594
2019-12-29 19:21:35: Loss time: 0.5605003833770752 Grad time: 1.1509201526641846
2019-12-29 19:21:35: Embed time: 0.000997781753540039
2019-12-29 19:21:36: Train loss: -103330.42404175353
2019-12-29 19:21:37: Loss time: 0.541576623916626 Grad time: 0.9703783988952637
2019-12-29 19:21:37: Embed time: 0.0
2019-12-29 19:21:37: Train loss: -103331.83108067975
2019-12-29 19:21:38: Loss time: 0.5974018573760986 Grad time: 1.0571718215942383
2019-12-29 19:21:38: Embed time: 0.0009975433349609375
2019-12-29 19:21:39: Train loss: -103333.24505157475
2019-12-29 19:21:40: Loss time: 0.5275881290435791 Grad time: 1.0452032089233398
2019-12-29 19:21:41: Validation loss: 1.0 Train loss: -103333.24505157475
2019-12-29 19:21:41: Best model so far (label loss):  1.0 at time 10
2019-12-29 19:21:41: Best model stored at output/models/2019-12-29_19_19_18-TRAIN-LR0_001-MB640.model
2019-12-29 19:21:41: Minibatches processed: 80
2019-12-29 19:21:41: Embed time: 0.000997304916381836
2019-12-29 19:21:42: Train loss: -103334.66501343095
2019-12-29 19:21:43: Loss time: 0.5006585121154785 Grad time: 1.3084990978240967
2019-12-29 19:21:43: Embed time: 0.0009970664978027344
2019-12-29 19:21:44: Train loss: -103336.09002409011
2019-12-29 19:21:45: Loss time: 0.5265944004058838 Grad time: 1.0631515979766846
2019-12-29 19:21:45: Embed time: 0.000997781753540039
2019-12-29 19:21:45: Train loss: -103337.51916373536
2019-12-29 19:21:46: Loss time: 0.5056464672088623 Grad time: 0.9843673706054688
2019-12-29 19:21:46: Embed time: 0.0
2019-12-29 19:21:47: Train loss: -103338.95155638226
2019-12-29 19:21:48: Loss time: 0.5345950126647949 Grad time: 0.9873330593109131
2019-12-29 19:21:48: Embed time: 0.000997304916381836
2019-12-29 19:21:48: Train loss: -103340.38639187012
2019-12-29 19:21:49: Loss time: 0.5405795574188232 Grad time: 1.169844150543213
2019-12-29 19:21:49: Embed time: 0.0009965896606445312
2019-12-29 19:21:50: Train loss: -103341.82293921037
2019-12-29 19:21:51: Loss time: 0.5345687866210938 Grad time: 1.0122923851013184
2019-12-29 19:21:51: Embed time: 0.0
2019-12-29 19:21:52: Train loss: -103343.26055991046
2019-12-29 19:21:53: Loss time: 0.5036523342132568 Grad time: 0.9813756942749023
2019-12-29 19:21:53: Embed time: 0.000997304916381836
2019-12-29 19:21:53: Train loss: -103344.69872180936
2019-12-29 19:21:54: Loss time: 0.5186121463775635 Grad time: 1.0312414169311523
2019-12-29 19:21:54: Embed time: 0.0009975433349609375
2019-12-29 19:21:55: Train loss: -103346.13699032522
2019-12-29 19:21:56: Loss time: 0.5266170501708984 Grad time: 0.9614019393920898
2019-12-29 19:21:56: Embed time: 0.0
2019-12-29 19:21:56: Train loss: -103347.57503037949
2019-12-29 19:21:57: Loss time: 0.5176143646240234 Grad time: 1.0920777320861816
2019-12-29 19:21:58: Validation loss: 1.0 Train loss: -103347.57503037949
2019-12-29 19:21:58: Best model so far (label loss):  1.0 at time 10
2019-12-29 19:21:58: Best model stored at output/models/2019-12-29_19_19_18-TRAIN-LR0_001-MB640.model
2019-12-29 19:21:58: Minibatches processed: 90
2019-12-29 19:21:58: Embed time: 0.000997304916381836
2019-12-29 19:21:59: Train loss: -103349.01258696258
2019-12-29 19:22:00: Loss time: 0.5346469879150391 Grad time: 0.9873569011688232
2019-12-29 19:22:00: Embed time: 0.0009975433349609375
2019-12-29 19:22:01: Train loss: -103350.44947712781
2019-12-29 19:22:02: Loss time: 0.4996621608734131 Grad time: 1.0003232955932617
2019-12-29 19:22:02: Embed time: 0.000997781753540039
2019-12-29 19:22:02: Train loss: -103351.88557201052
2019-12-29 19:22:03: Loss time: 0.512627124786377 Grad time: 1.1269845962524414
2019-12-29 19:22:03: Embed time: 0.0009975433349609375
2019-12-29 19:22:04: Train loss: -103353.3207779726
2019-12-29 19:22:05: Loss time: 0.5365641117095947 Grad time: 1.1519196033477783
2019-12-29 19:22:05: Embed time: 0.000997781753540039
2019-12-29 19:22:05: Train loss: -103354.75501750747
2019-12-29 19:22:06: Loss time: 0.518610954284668 Grad time: 1.0522105693817139
2019-12-29 19:22:06: Embed time: 0.0
2019-12-29 19:22:07: Train loss: -103356.18822421931
2019-12-29 19:22:08: Loss time: 0.5116326808929443 Grad time: 0.928513765335083
2019-12-29 19:22:08: Embed time: 0.0
2019-12-29 19:22:08: Train loss: -103357.62031671766
2019-12-29 19:22:09: Loss time: 0.5096368789672852 Grad time: 0.9514541625976562
2019-12-29 19:22:09: Embed time: 0.0
2019-12-29 19:22:10: Train loss: -103359.05120301219
2019-12-29 19:22:11: Loss time: 0.5644903182983398 Grad time: 0.9903490543365479
2019-12-29 19:22:11: Embed time: 0.000997781753540039
2019-12-29 19:22:11: Train loss: -103360.48076505962
2019-12-29 19:22:12: Loss time: 0.5405569076538086 Grad time: 0.970400333404541
2019-12-29 19:22:12: Embed time: 0.000997781753540039
2019-12-29 19:22:13: Train loss: -103361.90886638063
2019-12-29 19:22:14: Loss time: 0.5196101665496826 Grad time: 1.110029935836792
2019-12-29 19:22:15: Validation loss: 1.0 Train loss: -103361.90886638063
2019-12-29 19:22:15: Best model so far (label loss):  1.0 at time 10
2019-12-29 19:22:15: Best model stored at output/models/2019-12-29_19_19_18-TRAIN-LR0_001-MB640.model
2019-12-29 19:22:15: Minibatches processed: 100
2019-12-29 19:22:15: Embed time: 0.001020669937133789
2019-12-29 19:22:16: Train loss: -103363.33533658822
2019-12-29 19:22:17: Loss time: 0.4817202091217041 Grad time: 1.0781049728393555
2019-12-29 19:22:17: Embed time: 0.0009996891021728516
2019-12-29 19:22:18: Train loss: -103364.75998588178
2019-12-29 19:22:19: Loss time: 0.5235991477966309 Grad time: 0.9903488159179688
2019-12-29 19:22:19: Embed time: 0.0
2019-12-29 19:22:19: Train loss: -103366.18260295175
2019-12-29 19:22:20: Loss time: 0.510634183883667 Grad time: 0.9863615036010742
2019-12-29 19:22:20: Embed time: 0.0009970664978027344
2019-12-29 19:22:21: Train loss: -103367.60296123456
2019-12-29 19:22:22: Loss time: 0.5764579772949219 Grad time: 1.0252571105957031
2019-12-29 19:22:22: Embed time: 0.0009975433349609375
2019-12-29 19:22:22: Train loss: -103369.02082549814
2019-12-29 19:22:23: Loss time: 0.5305807590484619 Grad time: 0.9893536567687988
2019-12-29 19:22:23: Embed time: 0.000997304916381836
2019-12-29 19:22:24: Train loss: -103370.435949749
2019-12-29 19:22:25: Loss time: 0.5335719585418701 Grad time: 1.0142853260040283
2019-12-29 19:22:25: Embed time: 0.0009980201721191406
2019-12-29 19:22:25: Train loss: -103371.8480875064
2019-12-29 19:22:26: Loss time: 0.5206096172332764 Grad time: 1.1389503479003906
2019-12-29 19:22:26: Embed time: 0.0
2019-12-29 19:22:27: Train loss: -103373.25700424437
2019-12-29 19:22:28: Loss time: 0.522615909576416 Grad time: 0.9704210758209229
2019-12-29 19:22:28: Embed time: 0.0
2019-12-29 19:22:28: Train loss: -103374.6624700828
2019-12-29 19:22:29: Loss time: 0.5056204795837402 Grad time: 1.0312414169311523
2019-12-29 19:22:29: Embed time: 0.0009984970092773438
2019-12-29 19:22:30: Train loss: -103376.06427287325
2019-12-29 19:22:31: Loss time: 0.5086390972137451 Grad time: 0.9574387073516846
2019-12-29 19:22:32: Validation loss: 1.0 Train loss: -103376.06427287325
2019-12-29 19:22:32: Best model so far (label loss):  1.0 at time 10
2019-12-29 19:22:32: Best model stored at output/models/2019-12-29_19_19_18-TRAIN-LR0_001-MB640.model
2019-12-29 19:22:32: Minibatches processed: 110
