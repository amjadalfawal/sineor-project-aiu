2019-12-29 16:32:37: Embed time: 0.17552995681762695
2019-12-29 16:32:38: Train loss: -103280.72165301313
2019-12-29 16:32:40: Loss time: 1.8586111068725586 Grad time: 1.701521396636963
2019-12-29 16:32:40: Embed time: 0.0009992122650146484
2019-12-29 16:32:41: Train loss: -103280.93801818359
2019-12-29 16:32:42: Loss time: 0.727055549621582 Grad time: 1.6555914878845215
2019-12-29 16:32:42: Embed time: 0.0
2019-12-29 16:32:43: Train loss: -103281.15623318712
2019-12-29 16:32:45: Loss time: 0.6821243762969971 Grad time: 1.602940320968628
2019-12-29 16:32:45: Embed time: 0.0009958744049072266
2019-12-29 16:32:45: Train loss: -103281.37640992268
2019-12-29 16:32:47: Loss time: 0.6961371898651123 Grad time: 1.5627772808074951
2019-12-29 16:32:47: Embed time: 0.0009975433349609375
2019-12-29 16:32:48: Train loss: -103281.59870631059
2019-12-29 16:32:49: Loss time: 0.7793262004852295 Grad time: 1.4646897315979004
2019-12-29 16:32:49: Embed time: 0.0009965896606445312
2019-12-29 16:32:50: Train loss: -103281.8233247571
2019-12-29 16:32:52: Loss time: 0.6735186576843262 Grad time: 1.5467417240142822
2019-12-29 16:32:52: Embed time: 0.0009968280792236328
2019-12-29 16:32:52: Train loss: -103282.05049407593
2019-12-29 16:32:54: Loss time: 0.658806324005127 Grad time: 1.6133615970611572
2019-12-29 16:32:54: Embed time: 0.0
2019-12-29 16:32:54: Train loss: -103282.28045129777
2019-12-29 16:32:56: Loss time: 0.6561264991760254 Grad time: 1.4516427516937256
2019-12-29 16:32:56: Embed time: 0.0
2019-12-29 16:32:57: Train loss: -103282.51343393336
2019-12-29 16:32:58: Loss time: 0.671820878982544 Grad time: 1.5171208381652832
2019-12-29 16:32:58: Embed time: 0.0009963512420654297
2019-12-29 16:32:59: Train loss: -103282.74968785142
2019-12-29 16:33:00: Loss time: 0.744788408279419 Grad time: 1.5111491680145264
2019-12-29 16:33:01: Validation loss: 1.0 Train loss: -103282.74968785142
2019-12-29 16:33:01: Best model so far (label loss):  1.0 at time 10
2019-12-29 16:33:01: Best model stored at output/models/2019-12-29_16_32_36-TRAIN-LR0_001-MB640.model
2019-12-29 16:33:01: Minibatches processed: 10
2019-12-29 16:33:01: Embed time: 0.0009984970092773438
2019-12-29 16:33:02: Train loss: -103282.98947369702
2019-12-29 16:33:03: Loss time: 0.6552767753601074 Grad time: 1.4561655521392822
2019-12-29 16:33:03: Embed time: 0.0
2019-12-29 16:33:04: Train loss: -103283.2330674925
2019-12-29 16:33:06: Loss time: 0.707568883895874 Grad time: 1.4639768600463867
2019-12-29 16:33:06: Embed time: 0.0010266304016113281
2019-12-29 16:33:06: Train loss: -103283.48075978483
2019-12-29 16:33:08: Loss time: 0.6533195972442627 Grad time: 1.4380807876586914
2019-12-29 16:33:08: Embed time: 0.0
2019-12-29 16:33:08: Train loss: -103283.7328531722
2019-12-29 16:33:10: Loss time: 0.6496620178222656 Grad time: 1.5756807327270508
2019-12-29 16:33:10: Embed time: 0.0009999275207519531
2019-12-29 16:33:11: Train loss: -103283.98966166026
2019-12-29 16:33:12: Loss time: 0.6630997657775879 Grad time: 1.535445213317871
2019-12-29 16:33:12: Embed time: 0.0
2019-12-29 16:33:13: Train loss: -103284.25151111398
2019-12-29 16:33:14: Loss time: 0.6628170013427734 Grad time: 1.4761664867401123
2019-12-29 16:33:14: Embed time: 0.0009982585906982422
2019-12-29 16:33:15: Train loss: -103284.5187398928
2019-12-29 16:33:17: Loss time: 0.6996293067932129 Grad time: 1.5928285121917725
2019-12-29 16:33:17: Embed time: 0.000997304916381836
2019-12-29 16:33:17: Train loss: -103284.79169893886
2019-12-29 16:33:19: Loss time: 0.6562459468841553 Grad time: 1.5763037204742432
2019-12-29 16:33:19: Embed time: 0.0009970664978027344
2019-12-29 16:33:19: Train loss: -103285.07075351106
2019-12-29 16:33:21: Loss time: 0.6603798866271973 Grad time: 1.6421661376953125
2019-12-29 16:33:21: Embed time: 0.0
2019-12-29 16:33:22: Train loss: -103285.35628312555
2019-12-29 16:33:23: Loss time: 0.662407398223877 Grad time: 1.4737486839294434
2019-12-29 16:33:24: Validation loss: 1.0 Train loss: -103285.35628312555
2019-12-29 16:33:24: Best model so far (label loss):  1.0 at time 10
2019-12-29 16:33:24: Best model stored at output/models/2019-12-29_16_32_36-TRAIN-LR0_001-MB640.model
2019-12-29 16:33:24: Minibatches processed: 20
2019-12-29 16:33:24: Embed time: 0.000997304916381836
2019-12-29 16:33:25: Train loss: -103285.64868345135
2019-12-29 16:33:26: Loss time: 0.6506569385528564 Grad time: 1.6181831359863281
2019-12-29 16:33:26: Embed time: 0.0009975433349609375
2019-12-29 16:33:27: Train loss: -103285.94836727786
2019-12-29 16:33:28: Loss time: 0.6521182060241699 Grad time: 1.584526538848877
2019-12-29 16:33:28: Embed time: 0.0009276866912841797
2019-12-29 16:33:29: Train loss: -103286.25576740131
2019-12-29 16:33:31: Loss time: 0.6406161785125732 Grad time: 1.5999643802642822
2019-12-29 16:33:31: Embed time: 0.000997304916381836
2019-12-29 16:33:31: Train loss: -103286.57133754331
2019-12-29 16:33:33: Loss time: 0.7162458896636963 Grad time: 1.5001416206359863
2019-12-29 16:33:33: Embed time: 0.0009968280792236328
2019-12-29 16:33:34: Train loss: -103286.8955539557
2019-12-29 16:33:35: Loss time: 0.6574299335479736 Grad time: 1.4924633502960205
2019-12-29 16:33:35: Embed time: 0.0010008811950683594
2019-12-29 16:33:36: Train loss: -103287.22891568673
2019-12-29 16:33:37: Loss time: 0.678156852722168 Grad time: 1.6969366073608398
2019-12-29 16:33:38: Embed time: 0.0
2019-12-29 16:33:38: Train loss: -103287.57194259008
2019-12-29 16:33:39: Loss time: 0.6179306507110596 Grad time: 1.2606523036956787
2019-12-29 16:33:39: Embed time: 0.0009970664978027344
2019-12-29 16:33:40: Train loss: -103287.92517580418
2019-12-29 16:33:42: Loss time: 0.6649699211120605 Grad time: 1.6346814632415771
2019-12-29 16:33:42: Embed time: 0.0009970664978027344
2019-12-29 16:33:42: Train loss: -103288.28917624982
2019-12-29 16:33:44: Loss time: 0.6781861782073975 Grad time: 1.526515245437622
2019-12-29 16:33:44: Embed time: 0.0009984970092773438
2019-12-29 16:33:45: Train loss: -103288.66452361167
2019-12-29 16:33:46: Loss time: 0.6758882999420166 Grad time: 1.6041841506958008
2019-12-29 16:33:47: Validation loss: 1.0 Train loss: -103288.66452361167
2019-12-29 16:33:47: Best model so far (label loss):  1.0 at time 10
2019-12-29 16:33:47: Best model stored at output/models/2019-12-29_16_32_36-TRAIN-LR0_001-MB640.model
2019-12-29 16:33:47: Minibatches processed: 30
2019-12-29 16:33:47: Embed time: 0.0
2019-12-29 16:33:48: Train loss: -103289.05181694102
2019-12-29 16:33:49: Loss time: 0.6495072841644287 Grad time: 1.5900068283081055
2019-12-29 16:33:49: Embed time: 0.001994609832763672
2019-12-29 16:33:50: Train loss: -103289.45167378975
2019-12-29 16:33:51: Loss time: 0.658517599105835 Grad time: 1.5224449634552002
2019-12-29 16:33:51: Embed time: 0.001996755599975586
2019-12-29 16:33:52: Train loss: -103289.86473142129
2019-12-29 16:33:54: Loss time: 0.6692092418670654 Grad time: 1.6414225101470947
2019-12-29 16:33:54: Embed time: 0.0009987354278564453
2019-12-29 16:33:54: Train loss: -103290.29164698545
2019-12-29 16:33:56: Loss time: 0.7144818305969238 Grad time: 1.6472835540771484
2019-12-29 16:33:56: Embed time: 0.0009968280792236328
2019-12-29 16:33:57: Train loss: -103290.73309809482
2019-12-29 16:33:58: Loss time: 0.690908670425415 Grad time: 1.6974902153015137
2019-12-29 16:33:58: Embed time: 0.0009975433349609375
2019-12-29 16:33:59: Train loss: -103291.18978339792
2019-12-29 16:34:01: Loss time: 0.6906611919403076 Grad time: 1.7036046981811523
2019-12-29 16:34:01: Embed time: 0.0009970664978027344
2019-12-29 16:34:02: Train loss: -103291.66242255918
2019-12-29 16:34:03: Loss time: 0.6801819801330566 Grad time: 1.610144853591919
2019-12-29 16:34:03: Embed time: 0.0009970664978027344
2019-12-29 16:34:04: Train loss: -103292.15175609953
2019-12-29 16:34:05: Loss time: 0.6637041568756104 Grad time: 1.4951708316802979
2019-12-29 16:34:05: Embed time: 0.000995635986328125
2019-12-29 16:34:06: Train loss: -103292.65854646062
2019-12-29 16:34:08: Loss time: 0.6550800800323486 Grad time: 1.5102169513702393
2019-12-29 16:34:08: Embed time: 0.000997304916381836
2019-12-29 16:34:08: Train loss: -103293.18357377667
2019-12-29 16:34:10: Loss time: 0.6592364311218262 Grad time: 1.506861925125122
2019-12-29 16:34:10: Validation loss: 1.0 Train loss: -103293.18357377667
2019-12-29 16:34:10: Best model so far (label loss):  1.0 at time 10
2019-12-29 16:34:10: Best model stored at output/models/2019-12-29_16_32_36-TRAIN-LR0_001-MB640.model
2019-12-29 16:34:10: Minibatches processed: 40
2019-12-29 16:34:10: Embed time: 0.0009984970092773438
2019-12-29 16:34:11: Train loss: -103293.72763815917
2019-12-29 16:34:13: Loss time: 0.6761913299560547 Grad time: 1.56437087059021
2019-12-29 16:34:13: Embed time: 0.0009970664978027344
2019-12-29 16:34:13: Train loss: -103294.29155745667
2019-12-29 16:34:15: Loss time: 0.6623959541320801 Grad time: 1.5803003311157227
2019-12-29 16:34:15: Embed time: 0.0
2019-12-29 16:34:16: Train loss: -103294.87616285424
2019-12-29 16:34:17: Loss time: 0.6619064807891846 Grad time: 1.5613446235656738
2019-12-29 16:34:17: Embed time: 0.000997304916381836
2019-12-29 16:34:18: Train loss: -103295.48229755723
2019-12-29 16:34:20: Loss time: 0.6881365776062012 Grad time: 1.7106499671936035
2019-12-29 16:34:20: Embed time: 0.0009992122650146484
2019-12-29 16:34:20: Train loss: -103296.11081549487
2019-12-29 16:34:22: Loss time: 0.6914036273956299 Grad time: 1.6346099376678467
2019-12-29 16:34:22: Embed time: 0.0009949207305908203
2019-12-29 16:34:23: Train loss: -103296.76257586031
2019-12-29 16:34:24: Loss time: 0.6731963157653809 Grad time: 1.663060188293457
2019-12-29 16:34:24: Embed time: 0.0009975433349609375
2019-12-29 16:34:25: Train loss: -103297.43844649008
2019-12-29 16:34:26: Loss time: 0.6596133708953857 Grad time: 1.557471513748169
2019-12-29 16:34:26: Embed time: 0.001993894577026367
2019-12-29 16:34:27: Train loss: -103298.13930085982
2019-12-29 16:34:29: Loss time: 0.6791837215423584 Grad time: 2.151873826980591
2019-12-29 16:34:29: Embed time: 0.0009975433349609375
2019-12-29 16:34:30: Train loss: -103298.86601966125
2019-12-29 16:34:33: Loss time: 0.7823245525360107 Grad time: 2.587491750717163
2019-12-29 16:34:33: Embed time: 0.0011548995971679688
2019-12-29 16:34:33: Train loss: -103299.61948998802
2019-12-29 16:34:35: Loss time: 0.9375207424163818 Grad time: 1.6168506145477295
2019-12-29 16:34:36: Validation loss: 1.0 Train loss: -103299.61948998802
2019-12-29 16:34:36: Best model so far (label loss):  1.0 at time 10
2019-12-29 16:34:36: Best model stored at output/models/2019-12-29_16_32_36-TRAIN-LR0_001-MB640.model
2019-12-29 16:34:36: Minibatches processed: 50
2019-12-29 16:34:36: Embed time: 0.000997781753540039
2019-12-29 16:34:37: Train loss: -103300.40059922461
2019-12-29 16:34:39: Loss time: 0.7564849853515625 Grad time: 1.7564494609832764
2019-12-29 16:34:39: Embed time: 0.0
2019-12-29 16:34:39: Train loss: -103301.21022522888
2019-12-29 16:34:42: Loss time: 0.7455165386199951 Grad time: 2.2401039600372314
2019-12-29 16:34:42: Embed time: 0.0009980201721191406
2019-12-29 16:34:42: Train loss: -103302.04921595054
2019-12-29 16:34:44: Loss time: 0.6902956962585449 Grad time: 1.9157962799072266
2019-12-29 16:34:44: Embed time: 0.0009970664978027344
2019-12-29 16:34:45: Train loss: -103302.91836158592
2019-12-29 16:34:47: Loss time: 0.7146162986755371 Grad time: 2.0450072288513184
2019-12-29 16:34:47: Embed time: 0.0
2019-12-29 16:34:48: Train loss: -103303.8183465516
2019-12-29 16:34:49: Loss time: 0.7749261856079102 Grad time: 1.7399804592132568
2019-12-29 16:34:49: Embed time: 0.0019969940185546875
2019-12-29 16:34:50: Train loss: -103304.74968171056
2019-12-29 16:34:52: Loss time: 0.6649386882781982 Grad time: 1.5094764232635498
2019-12-29 16:34:52: Embed time: 0.000997304916381836
2019-12-29 16:34:52: Train loss: -103305.71262161281
2019-12-29 16:34:54: Loss time: 0.7141072750091553 Grad time: 1.908566951751709
2019-12-29 16:34:54: Embed time: 0.0009963512420654297
2019-12-29 16:34:55: Train loss: -103306.70705760595
2019-12-29 16:34:57: Loss time: 0.7519862651824951 Grad time: 1.7118854522705078
2019-12-29 16:34:57: Embed time: 0.0009980201721191406
2019-12-29 16:34:57: Train loss: -103307.73241037497
2019-12-29 16:34:59: Loss time: 0.6870334148406982 Grad time: 1.6049163341522217
2019-12-29 16:34:59: Embed time: 0.0009968280792236328
2019-12-29 16:35:00: Train loss: -103308.78753067518
2019-12-29 16:35:01: Loss time: 0.7153794765472412 Grad time: 1.587632656097412
2019-12-29 16:35:02: Validation loss: 1.0 Train loss: -103308.78753067518
2019-12-29 16:35:02: Best model so far (label loss):  1.0 at time 10
2019-12-29 16:35:02: Best model stored at output/models/2019-12-29_16_32_36-TRAIN-LR0_001-MB640.model
2019-12-29 16:35:02: Minibatches processed: 60
2019-12-29 16:35:02: Embed time: 0.0009965896606445312
2019-12-29 16:35:03: Train loss: -103309.87063836683
2019-12-29 16:35:04: Loss time: 0.7377297878265381 Grad time: 1.534379243850708
2019-12-29 16:35:04: Embed time: 0.0
2019-12-29 16:35:05: Train loss: -103310.97931622724
2019-12-29 16:35:07: Loss time: 0.6633660793304443 Grad time: 1.492663860321045
2019-12-29 16:35:07: Embed time: 0.000997304916381836
2019-12-29 16:35:07: Train loss: -103312.11058176868
2019-12-29 16:35:09: Loss time: 0.6517844200134277 Grad time: 1.4686996936798096
2019-12-29 16:35:09: Embed time: 0.0009961128234863281
2019-12-29 16:35:09: Train loss: -103313.26103956261
2019-12-29 16:35:11: Loss time: 0.6607275009155273 Grad time: 1.56788969039917
2019-12-29 16:35:11: Embed time: 0.0009970664978027344
2019-12-29 16:35:12: Train loss: -103314.42709535087
2019-12-29 16:35:13: Loss time: 0.6502606868743896 Grad time: 1.4713871479034424
2019-12-29 16:35:13: Embed time: 0.0009975433349609375
2019-12-29 16:35:14: Train loss: -103315.60518841298
2019-12-29 16:35:15: Loss time: 0.7240643501281738 Grad time: 1.7080483436584473
2019-12-29 16:35:15: Embed time: 0.000997304916381836
2019-12-29 16:35:16: Train loss: -103316.79201448576
2019-12-29 16:35:18: Loss time: 0.6885635852813721 Grad time: 1.6051669120788574
2019-12-29 16:35:18: Embed time: 0.0009965896606445312
2019-12-29 16:35:18: Train loss: -103317.98469616866
2019-12-29 16:35:20: Loss time: 0.6642401218414307 Grad time: 1.5507333278656006
2019-12-29 16:35:20: Embed time: 0.0
2019-12-29 16:35:21: Train loss: -103319.18087361517
2019-12-29 16:35:22: Loss time: 0.6777677536010742 Grad time: 1.507793664932251
2019-12-29 16:35:22: Embed time: 0.0019936561584472656
2019-12-29 16:35:23: Train loss: -103320.37873384396
2019-12-29 16:35:24: Loss time: 0.6552469730377197 Grad time: 1.5994796752929688
2019-12-29 16:35:25: Validation loss: 1.0 Train loss: -103320.37873384396
2019-12-29 16:35:25: Best model so far (label loss):  1.0 at time 10
2019-12-29 16:35:25: Best model stored at output/models/2019-12-29_16_32_36-TRAIN-LR0_001-MB640.model
2019-12-29 16:35:25: Minibatches processed: 70
2019-12-29 16:35:25: Embed time: 0.000997304916381836
2019-12-29 16:35:26: Train loss: -103321.57698097642
2019-12-29 16:35:27: Loss time: 0.6482679843902588 Grad time: 1.5631613731384277
2019-12-29 16:35:27: Embed time: 0.0
2019-12-29 16:35:28: Train loss: -103322.77476020994
2019-12-29 16:35:30: Loss time: 0.6731550693511963 Grad time: 1.5408861637115479
2019-12-29 16:35:30: Embed time: 0.0009970664978027344
2019-12-29 16:35:30: Train loss: -103323.97157659406
2019-12-29 16:35:32: Loss time: 0.6577503681182861 Grad time: 1.4836771488189697
2019-12-29 16:35:32: Embed time: 0.0009949207305908203
2019-12-29 16:35:32: Train loss: -103325.16721435568
2019-12-29 16:35:34: Loss time: 0.6958029270172119 Grad time: 1.477464199066162
2019-12-29 16:35:34: Embed time: 0.0
2019-12-29 16:35:35: Train loss: -103326.36164295608
2019-12-29 16:35:36: Loss time: 0.6903486251831055 Grad time: 1.5257604122161865
2019-12-29 16:35:36: Embed time: 0.001993894577026367
2019-12-29 16:35:37: Train loss: -103327.5549725995
2019-12-29 16:35:39: Loss time: 0.7325499057769775 Grad time: 1.667020559310913
2019-12-29 16:35:39: Embed time: 0.0
2019-12-29 16:35:39: Train loss: -103328.74739477123
2019-12-29 16:35:41: Loss time: 0.7180864810943604 Grad time: 1.7532002925872803
2019-12-29 16:35:41: Embed time: 0.0009970664978027344
2019-12-29 16:35:42: Train loss: -103329.93915098552
2019-12-29 16:35:43: Loss time: 0.7263822555541992 Grad time: 1.620649814605713
2019-12-29 16:35:43: Embed time: 0.0009975433349609375
2019-12-29 16:35:44: Train loss: -103331.13051423941
2019-12-29 16:35:46: Loss time: 0.7141516208648682 Grad time: 1.530142068862915
2019-12-29 16:35:46: Embed time: 0.0009970664978027344
2019-12-29 16:35:46: Train loss: -103332.321770031
2019-12-29 16:35:48: Loss time: 0.7021219730377197 Grad time: 1.9996204376220703
2019-12-29 16:35:49: Validation loss: 1.0 Train loss: -103332.321770031
2019-12-29 16:35:49: Best model so far (label loss):  1.0 at time 10
2019-12-29 16:35:49: Best model stored at output/models/2019-12-29_16_32_36-TRAIN-LR0_001-MB640.model
2019-12-29 16:35:49: Minibatches processed: 80
2019-12-29 16:35:49: Embed time: 0.0009875297546386719
2019-12-29 16:35:50: Train loss: -103333.51321408455
2019-12-29 16:35:52: Loss time: 0.6582450866699219 Grad time: 1.7143316268920898
2019-12-29 16:35:52: Embed time: 0.000997304916381836
2019-12-29 16:35:52: Train loss: -103334.7051466355
2019-12-29 16:35:54: Loss time: 0.8591907024383545 Grad time: 1.6114516258239746
2019-12-29 16:35:54: Embed time: 0.0009975433349609375
2019-12-29 16:35:55: Train loss: -103335.89787178856
2019-12-29 16:35:56: Loss time: 0.7167818546295166 Grad time: 1.5888886451721191
2019-12-29 16:35:56: Embed time: 0.0
2019-12-29 16:35:57: Train loss: -103337.09169752568
2019-12-29 16:35:59: Loss time: 0.6653876304626465 Grad time: 1.655311107635498
2019-12-29 16:35:59: Embed time: 0.0009982585906982422
2019-12-29 16:35:59: Train loss: -103338.28694084479
2019-12-29 16:36:01: Loss time: 0.7032582759857178 Grad time: 1.6737291812896729
2019-12-29 16:36:01: Embed time: 0.0009984970092773438
2019-12-29 16:36:02: Train loss: -103339.48392738552
2019-12-29 16:36:03: Loss time: 0.6654496192932129 Grad time: 1.5248339176177979
2019-12-29 16:36:03: Embed time: 0.0
2019-12-29 16:36:04: Train loss: -103340.68299014539
2019-12-29 16:36:05: Loss time: 0.703300952911377 Grad time: 1.4464962482452393
2019-12-29 16:36:05: Embed time: 0.0009963512420654297
2019-12-29 16:36:06: Train loss: -103341.88447133948
2019-12-29 16:36:07: Loss time: 0.6421043872833252 Grad time: 1.4223353862762451
2019-12-29 16:36:07: Embed time: 0.0009963512420654297
2019-12-29 16:36:08: Train loss: -103343.08873349427
2019-12-29 16:36:10: Loss time: 0.7449772357940674 Grad time: 1.5386106967926025
2019-12-29 16:36:10: Embed time: 0.0009970664978027344
2019-12-29 16:36:10: Train loss: -103344.29613964108
2019-12-29 16:36:12: Loss time: 0.646019697189331 Grad time: 1.560556411743164
2019-12-29 16:36:13: Validation loss: 1.0 Train loss: -103344.29613964108
2019-12-29 16:36:13: Best model so far (label loss):  1.0 at time 10
2019-12-29 16:36:13: Best model stored at output/models/2019-12-29_16_32_36-TRAIN-LR0_001-MB640.model
2019-12-29 16:36:13: Minibatches processed: 90
2019-12-29 16:36:13: Embed time: 0.0019948482513427734
2019-12-29 16:36:13: Train loss: -103345.50708016734
2019-12-29 16:36:15: Loss time: 0.6754419803619385 Grad time: 1.6408486366271973
2019-12-29 16:36:15: Embed time: 0.000997304916381836
2019-12-29 16:36:16: Train loss: -103346.72194430894
2019-12-29 16:36:17: Loss time: 0.6938579082489014 Grad time: 1.4771907329559326
2019-12-29 16:36:17: Embed time: 0.0009970664978027344
2019-12-29 16:36:18: Train loss: -103347.94114210049
2019-12-29 16:36:19: Loss time: 0.65472412109375 Grad time: 1.4387106895446777
2019-12-29 16:36:19: Embed time: 0.0
2019-12-29 16:36:20: Train loss: -103349.16509529845
2019-12-29 16:36:21: Loss time: 0.6569473743438721 Grad time: 1.3635106086730957
2019-12-29 16:36:21: Embed time: 0.0009970664978027344
2019-12-29 16:36:22: Train loss: -103350.39422568794
2019-12-29 16:36:23: Loss time: 0.6393842697143555 Grad time: 1.3259732723236084
2019-12-29 16:36:23: Embed time: 0.001993894577026367
2019-12-29 16:36:24: Train loss: -103351.62897241088
2019-12-29 16:36:25: Loss time: 0.6270842552185059 Grad time: 1.5066430568695068
2019-12-29 16:36:25: Embed time: 0.0009951591491699219
2019-12-29 16:36:26: Train loss: -103352.86977690102
2019-12-29 16:36:28: Loss time: 0.663313627243042 Grad time: 1.3717849254608154
2019-12-29 16:36:28: Embed time: 0.0009980201721191406
2019-12-29 16:36:28: Train loss: -103354.1170792825
2019-12-29 16:36:30: Loss time: 0.6321015357971191 Grad time: 1.3919367790222168
2019-12-29 16:36:30: Embed time: 0.0
2019-12-29 16:36:30: Train loss: -103355.37132319571
2019-12-29 16:36:31: Loss time: 0.6188745498657227 Grad time: 1.2500181198120117
2019-12-29 16:36:31: Embed time: 0.0009970664978027344
2019-12-29 16:36:32: Train loss: -103356.63294149109
2019-12-29 16:36:34: Loss time: 0.6351749897003174 Grad time: 1.4456679821014404
2019-12-29 16:36:34: Validation loss: 1.0 Train loss: -103356.63294149109
2019-12-29 16:36:34: Best model so far (label loss):  1.0 at time 10
2019-12-29 16:36:34: Best model stored at output/models/2019-12-29_16_32_36-TRAIN-LR0_001-MB640.model
2019-12-29 16:36:34: Minibatches processed: 100
2019-12-29 16:36:34: Embed time: 0.000997304916381836
2019-12-29 16:36:35: Train loss: -103357.90236463345
2019-12-29 16:36:36: Loss time: 0.5564978122711182 Grad time: 1.3523554801940918
2019-12-29 16:36:36: Embed time: 0.0009965896606445312
2019-12-29 16:36:37: Train loss: -103359.18000820627
2019-12-29 16:36:38: Loss time: 0.6371383666992188 Grad time: 1.2771687507629395
2019-12-29 16:36:38: Embed time: 0.000997781753540039
2019-12-29 16:36:39: Train loss: -103360.46627358688
2019-12-29 16:36:40: Loss time: 0.6375646591186523 Grad time: 1.2834627628326416
2019-12-29 16:36:40: Embed time: 0.003988981246948242
2019-12-29 16:36:41: Train loss: -103361.76152957078
2019-12-29 16:36:42: Loss time: 0.6325099468231201 Grad time: 1.2661194801330566
2019-12-29 16:36:42: Embed time: 0.0
2019-12-29 16:36:43: Train loss: -103363.066131003
2019-12-29 16:36:44: Loss time: 0.6196742057800293 Grad time: 1.3918139934539795
2019-12-29 16:36:44: Embed time: 0.0
2019-12-29 16:36:45: Train loss: -103364.38039411436
2019-12-29 16:36:46: Loss time: 0.6412506103515625 Grad time: 1.5322237014770508
2019-12-29 16:36:46: Embed time: 0.000997304916381836
2019-12-29 16:36:47: Train loss: -103365.70459800833
2019-12-29 16:36:48: Loss time: 0.6799986362457275 Grad time: 1.3134832382202148
2019-12-29 16:36:48: Embed time: 0.000997304916381836
2019-12-29 16:36:49: Train loss: -103367.03897574362
2019-12-29 16:36:50: Loss time: 0.6282317638397217 Grad time: 1.2683169841766357
2019-12-29 16:36:50: Embed time: 0.0009965896606445312
2019-12-29 16:36:51: Train loss: -103368.38371160533
2019-12-29 16:36:52: Loss time: 0.6234829425811768 Grad time: 1.337602138519287
2019-12-29 16:36:52: Embed time: 0.0009987354278564453
2019-12-29 16:36:53: Train loss: -103369.73893656336
2019-12-29 16:36:54: Loss time: 0.6347804069519043 Grad time: 1.28922700881958
2019-12-29 16:36:55: Validation loss: 1.0 Train loss: -103369.73893656336
2019-12-29 16:36:55: Best model so far (label loss):  1.0 at time 10
2019-12-29 16:36:55: Best model stored at output/models/2019-12-29_16_32_36-TRAIN-LR0_001-MB640.model
2019-12-29 16:36:55: Minibatches processed: 110
