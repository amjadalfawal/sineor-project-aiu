2019-12-29 20:26:44: Embed time: 0.0009679794311523438
2019-12-29 20:26:45: Train loss: -103279.36612759416
2019-12-29 20:26:46: Loss time: 0.8257617950439453 Grad time: 1.5917410850524902
2019-12-29 20:26:46: Embed time: 0.000997304916381836
2019-12-29 20:26:47: Train loss: -103279.54568441026
2019-12-29 20:26:49: Loss time: 0.9953365325927734 Grad time: 1.4092295169830322
2019-12-29 20:26:49: Embed time: 0.0009989738464355469
2019-12-29 20:26:49: Train loss: -103279.72728506777
2019-12-29 20:26:51: Loss time: 0.6771891117095947 Grad time: 1.3733887672424316
2019-12-29 20:26:51: Embed time: 0.0019943714141845703
2019-12-29 20:26:51: Train loss: -103279.91126880124
2019-12-29 20:26:53: Loss time: 0.6811778545379639 Grad time: 1.6765143871307373
2019-12-29 20:26:53: Embed time: 0.001031637191772461
2019-12-29 20:26:54: Train loss: -103280.09792088995
2019-12-29 20:26:55: Loss time: 0.7027478218078613 Grad time: 1.2819433212280273
2019-12-29 20:26:55: Embed time: 0.0010960102081298828
2019-12-29 20:26:56: Train loss: -103280.2874834968
2019-12-29 20:26:57: Loss time: 0.6796402931213379 Grad time: 1.3748626708984375
2019-12-29 20:26:57: Embed time: 0.000997781753540039
2019-12-29 20:26:58: Train loss: -103280.48018516382
2019-12-29 20:27:00: Loss time: 0.7400186061859131 Grad time: 1.6147692203521729
2019-12-29 20:27:00: Embed time: 0.001994609832763672
2019-12-29 20:27:00: Train loss: -103280.67625744765
2019-12-29 20:27:02: Loss time: 0.7380251884460449 Grad time: 1.3842968940734863
2019-12-29 20:27:02: Embed time: 0.0009913444519042969
2019-12-29 20:27:02: Train loss: -103280.87595403257
2019-12-29 20:27:04: Loss time: 0.6903121471405029 Grad time: 1.6045191287994385
2019-12-29 20:27:04: Embed time: 0.0009975433349609375
2019-12-29 20:27:05: Train loss: -103281.07956048254
2019-12-29 20:27:06: Loss time: 0.6961374282836914 Grad time: 1.5398788452148438
2019-12-29 20:27:08: Validation loss: 1.0 Train loss: -103281.07956048254
2019-12-29 20:27:08: Best model so far (label loss):  1.0 at time 10
2019-12-29 20:27:08: Best model stored at output/models/2019-12-29_20_26_44-TRAIN-LR0_001-MB640.model
2019-12-29 20:27:08: Minibatches processed: 10
2019-12-29 20:27:08: Embed time: 0.001007080078125
2019-12-29 20:27:09: Train loss: -103281.28739371734
2019-12-29 20:27:10: Loss time: 0.688126802444458 Grad time: 1.533724069595337
2019-12-29 20:27:10: Embed time: 0.002057790756225586
2019-12-29 20:27:11: Train loss: -103281.49979411007
2019-12-29 20:27:12: Loss time: 0.6603562831878662 Grad time: 1.5098085403442383
2019-12-29 20:27:12: Embed time: 0.0
2019-12-29 20:27:13: Train loss: -103281.7171130011
2019-12-29 20:27:15: Loss time: 0.8090701103210449 Grad time: 1.5755767822265625
2019-12-29 20:27:15: Embed time: 0.0
2019-12-29 20:27:15: Train loss: -103281.93970268224
2019-12-29 20:27:17: Loss time: 0.6675333976745605 Grad time: 1.3021972179412842
2019-12-29 20:27:17: Embed time: 0.0009970664978027344
2019-12-29 20:27:17: Train loss: -103282.16791271105
2019-12-29 20:27:19: Loss time: 0.7330362796783447 Grad time: 1.426241159439087
2019-12-29 20:27:19: Embed time: 7.367134094238281e-05
2019-12-29 20:27:19: Train loss: -103282.40209260666
2019-12-29 20:27:21: Loss time: 0.6646289825439453 Grad time: 1.580489158630371
2019-12-29 20:27:21: Embed time: 0.0
2019-12-29 20:27:22: Train loss: -103282.64259933015
2019-12-29 20:27:23: Loss time: 0.7300295829772949 Grad time: 1.3753180503845215
2019-12-29 20:27:23: Embed time: 0.0010805130004882812
2019-12-29 20:27:24: Train loss: -103282.8898038558
2019-12-29 20:27:25: Loss time: 0.6532649993896484 Grad time: 1.540604591369629
2019-12-29 20:27:25: Embed time: 0.001123666763305664
2019-12-29 20:27:26: Train loss: -103283.14409893387
2019-12-29 20:27:28: Loss time: 0.7764937877655029 Grad time: 1.5610723495483398
2019-12-29 20:27:28: Embed time: 0.0009987354278564453
2019-12-29 20:27:28: Train loss: -103283.40590349305
2019-12-29 20:27:30: Loss time: 0.6991152763366699 Grad time: 1.5443494319915771
2019-12-29 20:27:32: Validation loss: 1.0 Train loss: -103283.40590349305
2019-12-29 20:27:32: Best model so far (label loss):  1.0 at time 10
2019-12-29 20:27:32: Best model stored at output/models/2019-12-29_20_26_44-TRAIN-LR0_001-MB640.model
2019-12-29 20:27:32: Minibatches processed: 20
2019-12-29 20:27:32: Embed time: 0.000997781753540039
2019-12-29 20:27:32: Train loss: -103283.67566522954
2019-12-29 20:27:34: Loss time: 0.6594090461730957 Grad time: 1.473461389541626
2019-12-29 20:27:34: Embed time: 0.00031375885009765625
2019-12-29 20:27:35: Train loss: -103283.95386000219
2019-12-29 20:27:36: Loss time: 0.6778383255004883 Grad time: 1.5106334686279297
2019-12-29 20:27:36: Embed time: 0.0009965896606445312
2019-12-29 20:27:37: Train loss: -103284.24099061609
2019-12-29 20:27:38: Loss time: 0.6915488243103027 Grad time: 1.5285108089447021
2019-12-29 20:27:38: Embed time: 0.0009975433349609375
2019-12-29 20:27:39: Train loss: -103284.53758301114
2019-12-29 20:27:40: Loss time: 0.6813039779663086 Grad time: 1.3173487186431885
2019-12-29 20:27:40: Embed time: 0.0
2019-12-29 20:27:41: Train loss: -103284.84418430268
2019-12-29 20:27:42: Loss time: 0.6622297763824463 Grad time: 1.4082310199737549
2019-12-29 20:27:42: Embed time: 0.0017979145050048828
2019-12-29 20:27:43: Train loss: -103285.161359674
2019-12-29 20:27:44: Loss time: 0.6510069370269775 Grad time: 1.3186900615692139
2019-12-29 20:27:44: Embed time: 0.0010020732879638672
2019-12-29 20:27:45: Train loss: -103285.48969288672
2019-12-29 20:27:47: Loss time: 0.615607738494873 Grad time: 1.5646262168884277
2019-12-29 20:27:47: Embed time: 0.000997781753540039
2019-12-29 20:27:47: Train loss: -103285.8297869438
2019-12-29 20:27:49: Loss time: 0.755643367767334 Grad time: 1.4305078983306885
2019-12-29 20:27:49: Embed time: 0.0008771419525146484
2019-12-29 20:27:49: Train loss: -103286.18226540017
2019-12-29 20:27:51: Loss time: 0.6572661399841309 Grad time: 1.3332874774932861
2019-12-29 20:27:51: Embed time: 0.000997304916381836
2019-12-29 20:27:51: Train loss: -103286.54777480544
2019-12-29 20:27:53: Loss time: 0.6323325634002686 Grad time: 1.4710378646850586
2019-12-29 20:27:55: Validation loss: 1.0 Train loss: -103286.54777480544
2019-12-29 20:27:55: Best model so far (label loss):  1.0 at time 10
2019-12-29 20:27:55: Best model stored at output/models/2019-12-29_20_26_44-TRAIN-LR0_001-MB640.model
2019-12-29 20:27:55: Minibatches processed: 30
2019-12-29 20:27:55: Embed time: 0.0
2019-12-29 20:27:56: Train loss: -103286.92698592263
2019-12-29 20:27:57: Loss time: 0.6590240001678467 Grad time: 1.3344287872314453
2019-12-29 20:27:57: Embed time: 0.0010495185852050781
2019-12-29 20:27:58: Train loss: -103287.32059599427
2019-12-29 20:27:59: Loss time: 0.7565498352050781 Grad time: 1.3659422397613525
2019-12-29 20:27:59: Embed time: 0.0009047985076904297
2019-12-29 20:28:00: Train loss: -103287.72932892226
2019-12-29 20:28:01: Loss time: 0.6741037368774414 Grad time: 1.2526485919952393
2019-12-29 20:28:01: Embed time: 0.0009965896606445312
2019-12-29 20:28:02: Train loss: -103288.15393669013
2019-12-29 20:28:03: Loss time: 0.7154786586761475 Grad time: 1.5166199207305908
2019-12-29 20:28:03: Embed time: 0.0009968280792236328
2019-12-29 20:28:04: Train loss: -103288.59519918455
2019-12-29 20:28:05: Loss time: 0.7280521392822266 Grad time: 1.5189363956451416
2019-12-29 20:28:05: Embed time: 0.0009975433349609375
2019-12-29 20:28:06: Train loss: -103289.05392276667
2019-12-29 20:28:07: Loss time: 0.646270751953125 Grad time: 1.3204658031463623
2019-12-29 20:28:07: Embed time: 0.0009970664978027344
2019-12-29 20:28:08: Train loss: -103289.53094046761
2019-12-29 20:28:09: Loss time: 0.6875317096710205 Grad time: 1.304140329360962
2019-12-29 20:28:09: Embed time: 0.0009965896606445312
2019-12-29 20:28:10: Train loss: -103290.02710769449
2019-12-29 20:28:12: Loss time: 0.8053722381591797 Grad time: 1.4236626625061035
2019-12-29 20:28:12: Embed time: 0.0009849071502685547
2019-12-29 20:28:12: Train loss: -103290.54329958386
2019-12-29 20:28:14: Loss time: 0.6392772197723389 Grad time: 1.3683385848999023
2019-12-29 20:28:14: Embed time: 0.0
2019-12-29 20:28:14: Train loss: -103291.08040848773
2019-12-29 20:28:16: Loss time: 0.6444187164306641 Grad time: 1.394127607345581
2019-12-29 20:28:17: Validation loss: 1.0 Train loss: -103291.08040848773
2019-12-29 20:28:17: Best model so far (label loss):  1.0 at time 10
2019-12-29 20:28:17: Best model stored at output/models/2019-12-29_20_26_44-TRAIN-LR0_001-MB640.model
2019-12-29 20:28:17: Minibatches processed: 40
2019-12-29 20:28:17: Embed time: 0.001119852066040039
2019-12-29 20:28:18: Train loss: -103291.63933616897
2019-12-29 20:28:20: Loss time: 0.6562414169311523 Grad time: 1.5220160484313965
2019-12-29 20:28:20: Embed time: 0.0009968280792236328
2019-12-29 20:28:20: Train loss: -103292.22099000809
2019-12-29 20:28:22: Loss time: 0.6636254787445068 Grad time: 1.709096908569336
2019-12-29 20:28:22: Embed time: 0.0009965896606445312
2019-12-29 20:28:23: Train loss: -103292.82627499891
2019-12-29 20:28:24: Loss time: 0.7240612506866455 Grad time: 1.4431374073028564
2019-12-29 20:28:24: Embed time: 0.0011975765228271484
2019-12-29 20:28:25: Train loss: -103293.45608309335
2019-12-29 20:28:26: Loss time: 0.7210724353790283 Grad time: 1.460092306137085
2019-12-29 20:28:26: Embed time: 0.0019943714141845703
2019-12-29 20:28:27: Train loss: -103294.11128376587
2019-12-29 20:28:29: Loss time: 0.8169913291931152 Grad time: 1.5317540168762207
2019-12-29 20:28:29: Embed time: 0.0009970664978027344
2019-12-29 20:28:29: Train loss: -103294.79270960495
2019-12-29 20:28:31: Loss time: 0.7619607448577881 Grad time: 1.3932719230651855
2019-12-29 20:28:31: Embed time: 0.0009975433349609375
2019-12-29 20:28:32: Train loss: -103295.5011460968
2019-12-29 20:28:33: Loss time: 0.6731994152069092 Grad time: 1.5328986644744873
2019-12-29 20:28:33: Embed time: 0.0
2019-12-29 20:28:34: Train loss: -103296.23731758108
2019-12-29 20:28:35: Loss time: 0.8103165626525879 Grad time: 1.5214433670043945
2019-12-29 20:28:35: Embed time: 0.0009965896606445312
2019-12-29 20:28:36: Train loss: -103297.00187348096
2019-12-29 20:28:38: Loss time: 0.748715877532959 Grad time: 1.5291893482208252
2019-12-29 20:28:38: Embed time: 0.0010371208190917969
2019-12-29 20:28:38: Train loss: -103297.79537779788
2019-12-29 20:28:40: Loss time: 0.7340357303619385 Grad time: 1.422339916229248
2019-12-29 20:28:42: Validation loss: 1.0 Train loss: -103297.79537779788
2019-12-29 20:28:42: Best model so far (label loss):  1.0 at time 10
2019-12-29 20:28:42: Best model stored at output/models/2019-12-29_20_26_44-TRAIN-LR0_001-MB640.model
2019-12-29 20:28:42: Minibatches processed: 50
2019-12-29 20:28:42: Embed time: 0.0009894371032714844
2019-12-29 20:28:42: Train loss: -103298.61829591398
2019-12-29 20:28:44: Loss time: 0.763970136642456 Grad time: 1.596691370010376
2019-12-29 20:28:44: Embed time: 0.0010368824005126953
2019-12-29 20:28:45: Train loss: -103299.47098248023
2019-12-29 20:28:46: Loss time: 0.6947414875030518 Grad time: 1.3078999519348145
2019-12-29 20:28:46: Embed time: 0.0010576248168945312
2019-12-29 20:28:47: Train loss: -103300.3536688376
2019-12-29 20:28:48: Loss time: 0.6583003997802734 Grad time: 1.2974011898040771
2019-12-29 20:28:48: Embed time: 0.0
2019-12-29 20:28:49: Train loss: -103301.26645813312
2019-12-29 20:28:50: Loss time: 0.652611494064331 Grad time: 1.5235121250152588
2019-12-29 20:28:50: Embed time: 0.000997781753540039
2019-12-29 20:28:51: Train loss: -103302.20931285286
2019-12-29 20:28:52: Loss time: 0.6554257869720459 Grad time: 1.4499406814575195
2019-12-29 20:28:52: Embed time: 0.0009980201721191406
2019-12-29 20:28:53: Train loss: -103303.18205189395
2019-12-29 20:28:54: Loss time: 0.720935583114624 Grad time: 1.2747273445129395
2019-12-29 20:28:54: Embed time: 0.00096893310546875
2019-12-29 20:28:55: Train loss: -103304.18434861836
2019-12-29 20:28:56: Loss time: 0.6861379146575928 Grad time: 1.3473947048187256
2019-12-29 20:28:56: Embed time: 0.0009965896606445312
2019-12-29 20:28:57: Train loss: -103305.21572718254
2019-12-29 20:28:58: Loss time: 0.6488192081451416 Grad time: 1.411665439605713
2019-12-29 20:28:58: Embed time: 0.0019943714141845703
2019-12-29 20:28:59: Train loss: -103306.27556764346
2019-12-29 20:29:01: Loss time: 0.7216751575469971 Grad time: 1.5323915481567383
2019-12-29 20:29:01: Embed time: 0.0009970664978027344
2019-12-29 20:29:01: Train loss: -103307.36311127775
2019-12-29 20:29:03: Loss time: 0.6697871685028076 Grad time: 1.414635419845581
2019-12-29 20:29:04: Validation loss: 1.0 Train loss: -103307.36311127775
2019-12-29 20:29:04: Best model so far (label loss):  1.0 at time 10
2019-12-29 20:29:04: Best model stored at output/models/2019-12-29_20_26_44-TRAIN-LR0_001-MB640.model
2019-12-29 20:29:04: Minibatches processed: 60
2019-12-29 20:29:04: Embed time: 0.0009968280792236328
2019-12-29 20:29:05: Train loss: -103308.47746938239
2019-12-29 20:29:07: Loss time: 0.6352033615112305 Grad time: 1.540269374847412
2019-12-29 20:29:07: Embed time: 0.0
2019-12-29 20:29:07: Train loss: -103309.61763855966
2019-12-29 20:29:09: Loss time: 0.6458992958068848 Grad time: 1.4741864204406738
2019-12-29 20:29:09: Embed time: 0.0010728836059570312
2019-12-29 20:29:09: Train loss: -103310.78251780875
2019-12-29 20:29:11: Loss time: 0.6778852939605713 Grad time: 1.334824800491333
2019-12-29 20:29:11: Embed time: 0.0011425018310546875
2019-12-29 20:29:11: Train loss: -103311.97092798575
2019-12-29 20:29:13: Loss time: 0.7528338432312012 Grad time: 1.2977471351623535
2019-12-29 20:29:13: Embed time: 0.0010914802551269531
2019-12-29 20:29:13: Train loss: -103313.1816413085
2019-12-29 20:29:15: Loss time: 0.6881651878356934 Grad time: 1.5252184867858887
2019-12-29 20:29:15: Embed time: 0.0011239051818847656
2019-12-29 20:29:16: Train loss: -103314.41340587655
2019-12-29 20:29:17: Loss time: 0.6253266334533691 Grad time: 1.434164047241211
2019-12-29 20:29:17: Embed time: 0.0018029212951660156
2019-12-29 20:29:18: Train loss: -103315.66497037609
2019-12-29 20:29:19: Loss time: 0.6720094680786133 Grad time: 1.5598273277282715
2019-12-29 20:29:19: Embed time: 0.0017731189727783203
2019-12-29 20:29:20: Train loss: -103316.93510775821
2019-12-29 20:29:21: Loss time: 0.6500377655029297 Grad time: 1.4922215938568115
2019-12-29 20:29:21: Embed time: 0.0009984970092773438
2019-12-29 20:29:22: Train loss: -103318.22263309095
2019-12-29 20:29:24: Loss time: 1.0222642421722412 Grad time: 1.2576344013214111
2019-12-29 20:29:24: Embed time: 0.0014071464538574219
2019-12-29 20:29:24: Train loss: -103319.52641399454
2019-12-29 20:29:26: Loss time: 0.6393489837646484 Grad time: 1.4252393245697021
2019-12-29 20:29:28: Validation loss: 1.0 Train loss: -103319.52641399454
2019-12-29 20:29:28: Best model so far (label loss):  1.0 at time 10
2019-12-29 20:29:28: Best model stored at output/models/2019-12-29_20_26_44-TRAIN-LR0_001-MB640.model
2019-12-29 20:29:28: Minibatches processed: 70
2019-12-29 20:29:28: Embed time: 0.0009853839874267578
2019-12-29 20:29:28: Train loss: -103320.84538103356
2019-12-29 20:29:30: Loss time: 0.7096939086914062 Grad time: 1.5130035877227783
2019-12-29 20:29:30: Embed time: 0.0008938312530517578
2019-12-29 20:29:31: Train loss: -103322.17853294597
2019-12-29 20:29:32: Loss time: 0.655160665512085 Grad time: 1.246441125869751
2019-12-29 20:29:32: Embed time: 0.001062154769897461
2019-12-29 20:29:33: Train loss: -103323.52491809645
2019-12-29 20:29:34: Loss time: 0.7389888763427734 Grad time: 1.5592243671417236
2019-12-29 20:29:34: Embed time: 0.0009968280792236328
2019-12-29 20:29:35: Train loss: -103324.88362548794
2019-12-29 20:29:36: Loss time: 0.667780876159668 Grad time: 1.4649641513824463
2019-12-29 20:29:36: Embed time: 0.0012159347534179688
2019-12-29 20:29:37: Train loss: -103326.25377310936
2019-12-29 20:29:38: Loss time: 0.6781947612762451 Grad time: 1.4132106304168701
2019-12-29 20:29:38: Embed time: 0.0
2019-12-29 20:29:39: Train loss: -103327.63448102192
2019-12-29 20:29:41: Loss time: 0.8875937461853027 Grad time: 1.3593635559082031
2019-12-29 20:29:41: Embed time: 0.0019943714141845703
2019-12-29 20:29:41: Train loss: -103329.02486944594
2019-12-29 20:29:43: Loss time: 0.6593344211578369 Grad time: 1.4121229648590088
2019-12-29 20:29:43: Embed time: 0.0010213851928710938
2019-12-29 20:29:43: Train loss: -103330.42404175353
2019-12-29 20:29:45: Loss time: 0.6462712287902832 Grad time: 1.5050911903381348
2019-12-29 20:29:45: Embed time: 0.000997781753540039
2019-12-29 20:29:46: Train loss: -103331.83108067975
2019-12-29 20:29:47: Loss time: 0.7699398994445801 Grad time: 1.3463973999023438
2019-12-29 20:29:47: Embed time: 0.0010900497436523438
2019-12-29 20:29:48: Train loss: -103333.24505157475
2019-12-29 20:29:49: Loss time: 0.6741964817047119 Grad time: 1.5588293075561523
2019-12-29 20:29:51: Validation loss: 1.0 Train loss: -103333.24505157475
2019-12-29 20:29:51: Best model so far (label loss):  1.0 at time 10
2019-12-29 20:29:51: Best model stored at output/models/2019-12-29_20_26_44-TRAIN-LR0_001-MB640.model
2019-12-29 20:29:51: Minibatches processed: 80
2019-12-29 20:29:51: Embed time: 0.0009965896606445312
2019-12-29 20:29:52: Train loss: -103334.66501343095
2019-12-29 20:29:53: Loss time: 0.6123790740966797 Grad time: 1.413198709487915
2019-12-29 20:29:53: Embed time: 0.000997304916381836
2019-12-29 20:29:54: Train loss: -103336.09002409011
2019-12-29 20:29:55: Loss time: 0.6743757724761963 Grad time: 1.3581838607788086
2019-12-29 20:29:55: Embed time: 0.0009963512420654297
2019-12-29 20:29:56: Train loss: -103337.51916373536
2019-12-29 20:29:57: Loss time: 0.7596714496612549 Grad time: 1.3417284488677979
2019-12-29 20:29:57: Embed time: 0.0019948482513427734
2019-12-29 20:29:58: Train loss: -103338.95155638226
2019-12-29 20:29:59: Loss time: 0.7238690853118896 Grad time: 1.2982029914855957
2019-12-29 20:29:59: Embed time: 0.0009965896606445312
2019-12-29 20:30:00: Train loss: -103340.38639187012
2019-12-29 20:30:01: Loss time: 0.7123613357543945 Grad time: 1.5037076473236084
2019-12-29 20:30:02: Embed time: 0.0019943714141845703
2019-12-29 20:30:02: Train loss: -103341.82293921037
2019-12-29 20:30:03: Loss time: 0.6425557136535645 Grad time: 1.3271725177764893
2019-12-29 20:30:03: Embed time: 0.0009181499481201172
2019-12-29 20:30:04: Train loss: -103343.26055991046
2019-12-29 20:30:05: Loss time: 0.6266639232635498 Grad time: 1.3778958320617676
2019-12-29 20:30:06: Embed time: 0.0008449554443359375
2019-12-29 20:30:06: Train loss: -103344.69872180936
2019-12-29 20:30:08: Loss time: 0.6795480251312256 Grad time: 1.4627370834350586
2019-12-29 20:30:08: Embed time: 0.0009965896606445312
2019-12-29 20:30:08: Train loss: -103346.13699032522
2019-12-29 20:30:10: Loss time: 0.6680617332458496 Grad time: 1.3904297351837158
2019-12-29 20:30:10: Embed time: 0.0009975433349609375
2019-12-29 20:30:11: Train loss: -103347.57503037949
2019-12-29 20:30:12: Loss time: 0.793877363204956 Grad time: 1.5219273567199707
2019-12-29 20:30:14: Validation loss: 1.0 Train loss: -103347.57503037949
2019-12-29 20:30:14: Best model so far (label loss):  1.0 at time 10
2019-12-29 20:30:14: Best model stored at output/models/2019-12-29_20_26_44-TRAIN-LR0_001-MB640.model
2019-12-29 20:30:14: Minibatches processed: 90
2019-12-29 20:30:14: Embed time: 0.0010008811950683594
2019-12-29 20:30:14: Train loss: -103349.01258696258
2019-12-29 20:30:16: Loss time: 0.6073596477508545 Grad time: 1.2685902118682861
2019-12-29 20:30:16: Embed time: 0.0009980201721191406
2019-12-29 20:30:16: Train loss: -103350.44947712781
2019-12-29 20:30:18: Loss time: 0.7130932807922363 Grad time: 1.3583650588989258
2019-12-29 20:30:18: Embed time: 0.0009624958038330078
2019-12-29 20:30:18: Train loss: -103351.88557201052
2019-12-29 20:30:20: Loss time: 0.749431848526001 Grad time: 1.442667007446289
2019-12-29 20:30:20: Embed time: 0.00012230873107910156
2019-12-29 20:30:21: Train loss: -103353.3207779726
2019-12-29 20:30:22: Loss time: 0.618084192276001 Grad time: 1.5291709899902344
2019-12-29 20:30:22: Embed time: 0.0008788108825683594
2019-12-29 20:30:23: Train loss: -103354.75501750747
2019-12-29 20:30:24: Loss time: 0.604790449142456 Grad time: 1.3917465209960938
2019-12-29 20:30:24: Embed time: 0.0008757114410400391
2019-12-29 20:30:25: Train loss: -103356.18822421931
2019-12-29 20:30:26: Loss time: 0.6881814002990723 Grad time: 1.3741767406463623
2019-12-29 20:30:26: Embed time: 0.0009741783142089844
2019-12-29 20:30:27: Train loss: -103357.62031671766
2019-12-29 20:30:28: Loss time: 0.7001388072967529 Grad time: 1.251615285873413
2019-12-29 20:30:28: Embed time: 0.0
2019-12-29 20:30:29: Train loss: -103359.05120301219
2019-12-29 20:30:30: Loss time: 0.6712028980255127 Grad time: 1.4680731296539307
2019-12-29 20:30:30: Embed time: 0.0009963512420654297
2019-12-29 20:30:31: Train loss: -103360.48076505962
2019-12-29 20:30:32: Loss time: 0.6333043575286865 Grad time: 1.3493890762329102
2019-12-29 20:30:32: Embed time: 0.000997304916381836
2019-12-29 20:30:33: Train loss: -103361.90886638063
2019-12-29 20:30:34: Loss time: 0.6692335605621338 Grad time: 1.3533551692962646
2019-12-29 20:30:36: Validation loss: 1.0 Train loss: -103361.90886638063
2019-12-29 20:30:36: Best model so far (label loss):  1.0 at time 10
2019-12-29 20:30:36: Best model stored at output/models/2019-12-29_20_26_44-TRAIN-LR0_001-MB640.model
2019-12-29 20:30:36: Minibatches processed: 100
2019-12-29 20:30:36: Embed time: 0.000885009765625
2019-12-29 20:30:37: Train loss: -103363.33533658822
2019-12-29 20:30:38: Loss time: 0.6090455055236816 Grad time: 1.4493303298950195
2019-12-29 20:30:38: Embed time: 0.001851797103881836
2019-12-29 20:30:39: Train loss: -103364.75998588178
2019-12-29 20:30:40: Loss time: 0.7629580497741699 Grad time: 1.6356241703033447
2019-12-29 20:30:40: Embed time: 0.0
2019-12-29 20:30:41: Train loss: -103366.18260295175
2019-12-29 20:30:42: Loss time: 0.6445915699005127 Grad time: 1.323085069656372
2019-12-29 20:30:42: Embed time: 0.0009958744049072266
2019-12-29 20:30:43: Train loss: -103367.60296123456
2019-12-29 20:30:44: Loss time: 0.6247096061706543 Grad time: 1.4517340660095215
2019-12-29 20:30:44: Embed time: 0.0011026859283447266
2019-12-29 20:30:45: Train loss: -103369.02082549814
2019-12-29 20:30:47: Loss time: 0.7350833415985107 Grad time: 1.5708065032958984
2019-12-29 20:30:47: Embed time: 0.0009975433349609375
2019-12-29 20:30:47: Train loss: -103370.435949749
2019-12-29 20:30:49: Loss time: 0.6672153472900391 Grad time: 1.4023120403289795
2019-12-29 20:30:49: Embed time: 0.0
2019-12-29 20:30:49: Train loss: -103371.8480875064
2019-12-29 20:30:51: Loss time: 0.62870192527771 Grad time: 1.408843755722046
2019-12-29 20:30:51: Embed time: 0.0010249614715576172
2019-12-29 20:30:52: Train loss: -103373.25700424437
2019-12-29 20:30:53: Loss time: 0.7210700511932373 Grad time: 1.4651410579681396
2019-12-29 20:30:53: Embed time: 0.000997304916381836
2019-12-29 20:30:54: Train loss: -103374.6624700828
2019-12-29 20:30:55: Loss time: 0.6692087650299072 Grad time: 1.2576351165771484
2019-12-29 20:30:55: Embed time: 0.0
2019-12-29 20:30:56: Train loss: -103376.06427287325
2019-12-29 20:30:57: Loss time: 0.65264892578125 Grad time: 1.428781509399414
2019-12-29 20:30:59: Validation loss: 1.0 Train loss: -103376.06427287325
2019-12-29 20:30:59: Best model so far (label loss):  1.0 at time 10
2019-12-29 20:30:59: Best model stored at output/models/2019-12-29_20_26_44-TRAIN-LR0_001-MB640.model
2019-12-29 20:30:59: Minibatches processed: 110
