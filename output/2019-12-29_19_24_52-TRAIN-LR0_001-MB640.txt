2019-12-29 19:24:53: Embed time: 0.0009963512420654297
2019-12-29 19:24:53: Train loss: -103279.36612759416
2019-12-29 19:24:54: Loss time: 0.47971677780151367 Grad time: 1.0422091484069824
2019-12-29 19:24:54: Embed time: 0.0009975433349609375
2019-12-29 19:24:55: Train loss: -103279.54568441026
2019-12-29 19:24:56: Loss time: 0.5525383949279785 Grad time: 0.9673938751220703
2019-12-29 19:24:56: Embed time: 0.000997304916381836
2019-12-29 19:24:56: Train loss: -103279.72728506777
2019-12-29 19:24:57: Loss time: 0.531578779220581 Grad time: 1.0521836280822754
2019-12-29 19:24:57: Embed time: 0.0009970664978027344
2019-12-29 19:24:58: Train loss: -103279.91126880124
2019-12-29 19:24:59: Loss time: 0.5385587215423584 Grad time: 1.1958012580871582
2019-12-29 19:24:59: Embed time: 0.000997304916381836
2019-12-29 19:24:59: Train loss: -103280.09792088995
2019-12-29 19:25:00: Loss time: 0.5355672836303711 Grad time: 0.9993259906768799
2019-12-29 19:25:00: Embed time: 0.000997781753540039
2019-12-29 19:25:01: Train loss: -103280.2874834968
2019-12-29 19:25:02: Loss time: 0.5176150798797607 Grad time: 0.9594333171844482
2019-12-29 19:25:02: Embed time: 0.0009975433349609375
2019-12-29 19:25:02: Train loss: -103280.48018516382
2019-12-29 19:25:04: Loss time: 0.5226037502288818 Grad time: 1.0980603694915771
2019-12-29 19:25:04: Embed time: 0.000997304916381836
2019-12-29 19:25:04: Train loss: -103280.67625744765
2019-12-29 19:25:05: Loss time: 0.5176165103912354 Grad time: 0.9733941555023193
2019-12-29 19:25:05: Embed time: 0.0
2019-12-29 19:25:06: Train loss: -103280.87595403257
2019-12-29 19:25:07: Loss time: 0.52060866355896 Grad time: 1.054178237915039
2019-12-29 19:25:07: Embed time: 0.000997304916381836
2019-12-29 19:25:07: Train loss: -103281.07956048254
2019-12-29 19:25:08: Loss time: 0.5136275291442871 Grad time: 1.0252559185028076
2019-12-29 19:25:10: Validation loss: 1.0 Train loss: -103281.07956048254
2019-12-29 19:25:10: Best model so far (label loss):  1.0 at time 10
2019-12-29 19:25:10: Best model stored at output/models/2019-12-29_19_24_52-TRAIN-LR0_001-MB640.model
2019-12-29 19:25:10: Minibatches processed: 10
2019-12-29 19:25:10: Embed time: 0.0009970664978027344
2019-12-29 19:25:10: Train loss: -103281.28739371734
2019-12-29 19:25:11: Loss time: 0.48172855377197266 Grad time: 0.9993085861206055
2019-12-29 19:25:11: Embed time: 0.0009975433349609375
2019-12-29 19:25:12: Train loss: -103281.49979411007
2019-12-29 19:25:13: Loss time: 0.5226032733917236 Grad time: 0.9394848346710205
2019-12-29 19:25:13: Embed time: 0.0009975433349609375
2019-12-29 19:25:13: Train loss: -103281.7171130011
2019-12-29 19:25:14: Loss time: 0.5116326808929443 Grad time: 1.0312392711639404
2019-12-29 19:25:14: Embed time: 0.0009975433349609375
2019-12-29 19:25:15: Train loss: -103281.93970268224
2019-12-29 19:25:16: Loss time: 0.5944087505340576 Grad time: 1.1878209114074707
2019-12-29 19:25:16: Embed time: 0.0009975433349609375
2019-12-29 19:25:16: Train loss: -103282.16791271105
2019-12-29 19:25:17: Loss time: 0.5196113586425781 Grad time: 1.0481956005096436
2019-12-29 19:25:17: Embed time: 0.0009968280792236328
2019-12-29 19:25:18: Train loss: -103282.40209260666
2019-12-29 19:25:19: Loss time: 0.5475366115570068 Grad time: 1.0471985340118408
2019-12-29 19:25:19: Embed time: 0.000997304916381836
2019-12-29 19:25:20: Train loss: -103282.64259933015
2019-12-29 19:25:21: Loss time: 0.6073744297027588 Grad time: 1.0631816387176514
2019-12-29 19:25:21: Embed time: 0.0
2019-12-29 19:25:21: Train loss: -103282.8898038558
2019-12-29 19:25:22: Loss time: 0.5425491333007812 Grad time: 1.0372231006622314
2019-12-29 19:25:22: Embed time: 0.000997304916381836
2019-12-29 19:25:23: Train loss: -103283.14409893387
2019-12-29 19:25:24: Loss time: 0.5355691909790039 Grad time: 1.0152826309204102
2019-12-29 19:25:24: Embed time: 0.0009975433349609375
2019-12-29 19:25:24: Train loss: -103283.40590349305
2019-12-29 19:25:26: Loss time: 0.5196092128753662 Grad time: 1.1888196468353271
2019-12-29 19:25:27: Validation loss: 1.0 Train loss: -103283.40590349305
2019-12-29 19:25:27: Best model so far (label loss):  1.0 at time 10
2019-12-29 19:25:27: Best model stored at output/models/2019-12-29_19_24_52-TRAIN-LR0_001-MB640.model
2019-12-29 19:25:27: Minibatches processed: 20
2019-12-29 19:25:27: Embed time: 0.00098419189453125
2019-12-29 19:25:27: Train loss: -103283.67566522954
2019-12-29 19:25:29: Loss time: 0.48468899726867676 Grad time: 1.0870916843414307
2019-12-29 19:25:29: Embed time: 0.000997304916381836
2019-12-29 19:25:29: Train loss: -103283.95386000219
2019-12-29 19:25:30: Loss time: 0.5385606288909912 Grad time: 1.1559052467346191
2019-12-29 19:25:30: Embed time: 0.0009996891021728516
2019-12-29 19:25:31: Train loss: -103284.24099061609
2019-12-29 19:25:32: Loss time: 0.5914196968078613 Grad time: 1.170865774154663
2019-12-29 19:25:32: Embed time: 0.0
2019-12-29 19:25:33: Train loss: -103284.53758301114
2019-12-29 19:25:34: Loss time: 0.5226006507873535 Grad time: 1.088089942932129
2019-12-29 19:25:34: Embed time: 0.0009970664978027344
2019-12-29 19:25:34: Train loss: -103284.84418430268
2019-12-29 19:25:35: Loss time: 0.5345673561096191 Grad time: 1.1249918937683105
2019-12-29 19:25:35: Embed time: 0.0
2019-12-29 19:25:36: Train loss: -103285.161359674
2019-12-29 19:25:37: Loss time: 0.6003932952880859 Grad time: 1.1598963737487793
2019-12-29 19:25:37: Embed time: 0.000997781753540039
2019-12-29 19:25:38: Train loss: -103285.48969288672
2019-12-29 19:25:39: Loss time: 0.5315525531768799 Grad time: 1.0811066627502441
2019-12-29 19:25:39: Embed time: 0.0
2019-12-29 19:25:39: Train loss: -103285.8297869438
2019-12-29 19:25:40: Loss time: 0.5275886058807373 Grad time: 1.0402171611785889
2019-12-29 19:25:40: Embed time: 0.0
2019-12-29 19:25:41: Train loss: -103286.18226540017
2019-12-29 19:25:42: Loss time: 0.4946777820587158 Grad time: 1.1489248275756836
2019-12-29 19:25:42: Embed time: 0.000997304916381836
2019-12-29 19:25:42: Train loss: -103286.54777480544
2019-12-29 19:25:43: Loss time: 0.5206279754638672 Grad time: 0.9693851470947266
2019-12-29 19:25:45: Validation loss: 1.0 Train loss: -103286.54777480544
2019-12-29 19:25:45: Best model so far (label loss):  1.0 at time 10
2019-12-29 19:25:45: Best model stored at output/models/2019-12-29_19_24_52-TRAIN-LR0_001-MB640.model
2019-12-29 19:25:45: Minibatches processed: 30
2019-12-29 19:25:45: Embed time: 0.0009970664978027344
2019-12-29 19:25:45: Train loss: -103286.92698592263
2019-12-29 19:25:46: Loss time: 0.4886934757232666 Grad time: 1.1140196323394775
2019-12-29 19:25:46: Embed time: 0.000997304916381836
2019-12-29 19:25:47: Train loss: -103287.32059599427
2019-12-29 19:25:48: Loss time: 0.5964045524597168 Grad time: 1.1219987869262695
2019-12-29 19:25:48: Embed time: 0.0009970664978027344
2019-12-29 19:25:49: Train loss: -103287.72932892226
2019-12-29 19:25:50: Loss time: 0.5365629196166992 Grad time: 1.0053107738494873
2019-12-29 19:25:50: Embed time: 0.000997781753540039
2019-12-29 19:25:50: Train loss: -103288.15393669013
2019-12-29 19:25:51: Loss time: 0.516618013381958 Grad time: 1.0551753044128418
2019-12-29 19:25:51: Embed time: 0.0009975433349609375
2019-12-29 19:25:52: Train loss: -103288.59519918455
2019-12-29 19:25:53: Loss time: 0.52359938621521 Grad time: 1.200786828994751
2019-12-29 19:25:53: Embed time: 0.000997304916381836
2019-12-29 19:25:53: Train loss: -103289.05392276667
2019-12-29 19:25:54: Loss time: 0.5415520668029785 Grad time: 0.9414823055267334
2019-12-29 19:25:54: Embed time: 0.000997781753540039
2019-12-29 19:25:55: Train loss: -103289.53094046761
2019-12-29 19:25:56: Loss time: 0.5036523342132568 Grad time: 0.9654176235198975
2019-12-29 19:25:56: Embed time: 0.000997781753540039
2019-12-29 19:25:56: Train loss: -103290.02710769449
2019-12-29 19:25:58: Loss time: 0.5295841693878174 Grad time: 1.1499226093292236
2019-12-29 19:25:58: Embed time: 0.0
2019-12-29 19:25:58: Train loss: -103290.54329958386
2019-12-29 19:25:59: Loss time: 0.5305798053741455 Grad time: 1.0023183822631836
2019-12-29 19:25:59: Embed time: 0.0009968280792236328
2019-12-29 19:26:00: Train loss: -103291.08040848773
2019-12-29 19:26:01: Loss time: 0.5315766334533691 Grad time: 1.077118158340454
2019-12-29 19:26:02: Validation loss: 1.0 Train loss: -103291.08040848773
2019-12-29 19:26:02: Best model so far (label loss):  1.0 at time 10
2019-12-29 19:26:02: Best model stored at output/models/2019-12-29_19_24_52-TRAIN-LR0_001-MB640.model
2019-12-29 19:26:02: Minibatches processed: 40
2019-12-29 19:26:02: Embed time: 0.000997304916381836
2019-12-29 19:26:03: Train loss: -103291.63933616897
2019-12-29 19:26:04: Loss time: 0.48068690299987793 Grad time: 1.078115463256836
2019-12-29 19:26:04: Embed time: 0.0
2019-12-29 19:26:04: Train loss: -103292.22099000809
2019-12-29 19:26:05: Loss time: 0.5166170597076416 Grad time: 1.0950701236724854
2019-12-29 19:26:05: Embed time: 0.0
2019-12-29 19:26:06: Train loss: -103292.82627499891
2019-12-29 19:26:07: Loss time: 0.5395565032958984 Grad time: 0.9943389892578125
2019-12-29 19:26:07: Embed time: 0.0009975433349609375
2019-12-29 19:26:07: Train loss: -103293.45608309335
2019-12-29 19:26:08: Loss time: 0.5066452026367188 Grad time: 1.1289806365966797
2019-12-29 19:26:08: Embed time: 0.0
2019-12-29 19:26:09: Train loss: -103294.11128376587
2019-12-29 19:26:10: Loss time: 0.5445442199707031 Grad time: 1.1419422626495361
2019-12-29 19:26:10: Embed time: 0.000997304916381836
2019-12-29 19:26:11: Train loss: -103294.79270960495
2019-12-29 19:26:12: Loss time: 0.5136251449584961 Grad time: 0.940483808517456
2019-12-29 19:26:12: Embed time: 0.000997304916381836
2019-12-29 19:26:12: Train loss: -103295.5011460968
2019-12-29 19:26:13: Loss time: 0.5206079483032227 Grad time: 0.9175443649291992
2019-12-29 19:26:13: Embed time: 0.000997304916381836
2019-12-29 19:26:14: Train loss: -103296.23731758108
2019-12-29 19:26:15: Loss time: 0.5226020812988281 Grad time: 1.1658806800842285
2019-12-29 19:26:15: Embed time: 0.0
2019-12-29 19:26:15: Train loss: -103297.00187348096
2019-12-29 19:26:16: Loss time: 0.5315766334533691 Grad time: 0.9863612651824951
2019-12-29 19:26:16: Embed time: 0.0009975433349609375
2019-12-29 19:26:17: Train loss: -103297.79537779788
2019-12-29 19:26:18: Loss time: 0.5186140537261963 Grad time: 1.0920770168304443
2019-12-29 19:26:19: Validation loss: 1.0 Train loss: -103297.79537779788
2019-12-29 19:26:19: Best model so far (label loss):  1.0 at time 10
2019-12-29 19:26:19: Best model stored at output/models/2019-12-29_19_24_52-TRAIN-LR0_001-MB640.model
2019-12-29 19:26:19: Minibatches processed: 50
2019-12-29 19:26:19: Embed time: 0.0
2019-12-29 19:26:20: Train loss: -103298.61829591398
2019-12-29 19:26:21: Loss time: 0.52659010887146 Grad time: 1.1100306510925293
2019-12-29 19:26:21: Embed time: 0.0
2019-12-29 19:26:21: Train loss: -103299.47098248023
2019-12-29 19:26:22: Loss time: 0.5076406002044678 Grad time: 0.9883556365966797
2019-12-29 19:26:22: Embed time: 0.000997781753540039
2019-12-29 19:26:23: Train loss: -103300.3536688376
2019-12-29 19:26:24: Loss time: 0.5116329193115234 Grad time: 0.9723989963531494
2019-12-29 19:26:24: Embed time: 0.0009980201721191406
2019-12-29 19:26:24: Train loss: -103301.26645813312
2019-12-29 19:26:25: Loss time: 0.5186119079589844 Grad time: 1.1249885559082031
2019-12-29 19:26:25: Embed time: 0.0009970664978027344
2019-12-29 19:26:26: Train loss: -103302.20931285286
2019-12-29 19:26:27: Loss time: 0.5166158676147461 Grad time: 0.937492847442627
2019-12-29 19:26:27: Embed time: 0.0009968280792236328
2019-12-29 19:26:27: Train loss: -103303.18205189395
2019-12-29 19:26:28: Loss time: 0.520606517791748 Grad time: 1.0481960773468018
2019-12-29 19:26:28: Embed time: 0.000997304916381836
2019-12-29 19:26:29: Train loss: -103304.18434861836
2019-12-29 19:26:30: Loss time: 0.5136277675628662 Grad time: 1.047196388244629
2019-12-29 19:26:30: Embed time: 0.0
2019-12-29 19:26:31: Train loss: -103305.21572718254
2019-12-29 19:26:32: Loss time: 0.5455412864685059 Grad time: 1.0821034908294678
2019-12-29 19:26:32: Embed time: 0.0009965896606445312
2019-12-29 19:26:32: Train loss: -103306.27556764346
2019-12-29 19:26:33: Loss time: 0.5285844802856445 Grad time: 0.9883575439453125
2019-12-29 19:26:33: Embed time: 0.0009980201721191406
2019-12-29 19:26:34: Train loss: -103307.36311127775
2019-12-29 19:26:35: Loss time: 0.537559986114502 Grad time: 1.0292489528656006
2019-12-29 19:26:36: Validation loss: 1.0 Train loss: -103307.36311127775
2019-12-29 19:26:36: Best model so far (label loss):  1.0 at time 10
2019-12-29 19:26:36: Best model stored at output/models/2019-12-29_19_24_52-TRAIN-LR0_001-MB640.model
2019-12-29 19:26:36: Minibatches processed: 60
2019-12-29 19:26:36: Embed time: 0.0
2019-12-29 19:26:37: Train loss: -103308.47746938239
2019-12-29 19:26:38: Loss time: 0.4796891212463379 Grad time: 1.1569037437438965
2019-12-29 19:26:38: Embed time: 0.0009970664978027344
2019-12-29 19:26:38: Train loss: -103309.61763855966
2019-12-29 19:26:39: Loss time: 0.5076422691345215 Grad time: 1.0362262725830078
2019-12-29 19:26:39: Embed time: 0.0009982585906982422
2019-12-29 19:26:40: Train loss: -103310.78251780875
2019-12-29 19:26:41: Loss time: 0.51564621925354 Grad time: 0.9334778785705566
2019-12-29 19:26:41: Embed time: 0.0009975433349609375
2019-12-29 19:26:41: Train loss: -103311.97092798575
2019-12-29 19:26:42: Loss time: 0.5604991912841797 Grad time: 1.0511882305145264
2019-12-29 19:26:42: Embed time: 0.0009970664978027344
2019-12-29 19:26:43: Train loss: -103313.1816413085
2019-12-29 19:26:44: Loss time: 0.4966704845428467 Grad time: 0.970405101776123
2019-12-29 19:26:44: Embed time: 0.0
2019-12-29 19:26:44: Train loss: -103314.41340587655
2019-12-29 19:26:45: Loss time: 0.5176143646240234 Grad time: 0.9684109687805176
2019-12-29 19:26:45: Embed time: 0.0009975433349609375
2019-12-29 19:26:46: Train loss: -103315.66497037609
2019-12-29 19:26:47: Loss time: 0.5206058025360107 Grad time: 1.1409471035003662
2019-12-29 19:26:47: Embed time: 0.0
2019-12-29 19:26:48: Train loss: -103316.93510775821
2019-12-29 19:26:49: Loss time: 0.4976682662963867 Grad time: 1.0043129920959473
2019-12-29 19:26:49: Embed time: 0.0009975433349609375
2019-12-29 19:26:49: Train loss: -103318.22263309095
2019-12-29 19:26:50: Loss time: 0.5245988368988037 Grad time: 1.1269826889038086
2019-12-29 19:26:50: Embed time: 0.000997304916381836
2019-12-29 19:26:51: Train loss: -103319.52641399454
2019-12-29 19:26:52: Loss time: 0.517615556716919 Grad time: 0.9195394515991211
2019-12-29 19:26:53: Validation loss: 1.0 Train loss: -103319.52641399454
2019-12-29 19:26:53: Best model so far (label loss):  1.0 at time 10
2019-12-29 19:26:53: Best model stored at output/models/2019-12-29_19_24_52-TRAIN-LR0_001-MB640.model
2019-12-29 19:26:53: Minibatches processed: 70
2019-12-29 19:26:53: Embed time: 0.0009980201721191406
2019-12-29 19:26:54: Train loss: -103320.84538103356
2019-12-29 19:26:55: Loss time: 0.5126020908355713 Grad time: 1.0711345672607422
2019-12-29 19:26:55: Embed time: 0.0
2019-12-29 19:26:55: Train loss: -103322.17853294597
2019-12-29 19:26:56: Loss time: 0.5206115245819092 Grad time: 1.0811028480529785
2019-12-29 19:26:56: Embed time: 0.0
2019-12-29 19:26:57: Train loss: -103323.52491809645
2019-12-29 19:26:58: Loss time: 0.5116322040557861 Grad time: 1.2556390762329102
2019-12-29 19:26:58: Embed time: 0.0
2019-12-29 19:26:59: Train loss: -103324.88362548794
2019-12-29 19:27:00: Loss time: 0.5285844802856445 Grad time: 0.9793810844421387
2019-12-29 19:27:00: Embed time: 0.000997781753540039
2019-12-29 19:27:00: Train loss: -103326.25377310936
2019-12-29 19:27:01: Loss time: 0.5166199207305908 Grad time: 0.9933404922485352
2019-12-29 19:27:01: Embed time: 0.000997304916381836
2019-12-29 19:27:02: Train loss: -103327.63448102192
2019-12-29 19:27:03: Loss time: 0.5056469440460205 Grad time: 1.025256633758545
2019-12-29 19:27:03: Embed time: 0.0009970664978027344
2019-12-29 19:27:03: Train loss: -103329.02486944594
2019-12-29 19:27:04: Loss time: 0.5505259037017822 Grad time: 0.9045815467834473
2019-12-29 19:27:04: Embed time: 0.0
2019-12-29 19:27:05: Train loss: -103330.42404175353
2019-12-29 19:27:06: Loss time: 0.5305790901184082 Grad time: 1.0601646900177002
2019-12-29 19:27:06: Embed time: 0.000997304916381836
2019-12-29 19:27:06: Train loss: -103331.83108067975
2019-12-29 19:27:07: Loss time: 0.5086383819580078 Grad time: 1.10404634475708
2019-12-29 19:27:07: Embed time: 0.0009970664978027344
2019-12-29 19:27:08: Train loss: -103333.24505157475
2019-12-29 19:27:09: Loss time: 0.520606279373169 Grad time: 1.1369578838348389
2019-12-29 19:27:10: Validation loss: 1.0 Train loss: -103333.24505157475
2019-12-29 19:27:10: Best model so far (label loss):  1.0 at time 10
2019-12-29 19:27:10: Best model stored at output/models/2019-12-29_19_24_52-TRAIN-LR0_001-MB640.model
2019-12-29 19:27:10: Minibatches processed: 80
2019-12-29 19:27:10: Embed time: 0.0
2019-12-29 19:27:11: Train loss: -103334.66501343095
2019-12-29 19:27:12: Loss time: 0.49564027786254883 Grad time: 0.9913485050201416
2019-12-29 19:27:12: Embed time: 0.0
2019-12-29 19:27:12: Train loss: -103336.09002409011
2019-12-29 19:27:13: Loss time: 0.5076420307159424 Grad time: 0.9743921756744385
2019-12-29 19:27:13: Embed time: 0.0
2019-12-29 19:27:14: Train loss: -103337.51916373536
2019-12-29 19:27:15: Loss time: 0.5565109252929688 Grad time: 1.0302448272705078
2019-12-29 19:27:15: Embed time: 0.000997781753540039
2019-12-29 19:27:15: Train loss: -103338.95155638226
2019-12-29 19:27:16: Loss time: 0.5076425075531006 Grad time: 1.0142855644226074
2019-12-29 19:27:16: Embed time: 0.0009968280792236328
2019-12-29 19:27:17: Train loss: -103340.38639187012
2019-12-29 19:27:18: Loss time: 0.5116043090820312 Grad time: 1.1658806800842285
2019-12-29 19:27:18: Embed time: 0.0009968280792236328
2019-12-29 19:27:19: Train loss: -103341.82293921037
2019-12-29 19:27:20: Loss time: 0.5335721969604492 Grad time: 1.1279816627502441
2019-12-29 19:27:20: Embed time: 0.0
2019-12-29 19:27:20: Train loss: -103343.26055991046
2019-12-29 19:27:21: Loss time: 0.5375635623931885 Grad time: 0.9873554706573486
2019-12-29 19:27:21: Embed time: 0.0009980201721191406
2019-12-29 19:27:22: Train loss: -103344.69872180936
2019-12-29 19:27:23: Loss time: 0.5046496391296387 Grad time: 0.981374979019165
2019-12-29 19:27:23: Embed time: 0.0009970664978027344
2019-12-29 19:27:23: Train loss: -103346.13699032522
2019-12-29 19:27:24: Loss time: 0.5126285552978516 Grad time: 1.1598975658416748
2019-12-29 19:27:24: Embed time: 0.0009970664978027344
2019-12-29 19:27:25: Train loss: -103347.57503037949
2019-12-29 19:27:26: Loss time: 0.5515241622924805 Grad time: 0.9534492492675781
2019-12-29 19:27:27: Validation loss: 1.0 Train loss: -103347.57503037949
2019-12-29 19:27:27: Best model so far (label loss):  1.0 at time 10
2019-12-29 19:27:27: Best model stored at output/models/2019-12-29_19_24_52-TRAIN-LR0_001-MB640.model
2019-12-29 19:27:27: Minibatches processed: 90
2019-12-29 19:27:27: Embed time: 0.0
2019-12-29 19:27:28: Train loss: -103349.01258696258
2019-12-29 19:27:29: Loss time: 0.49567222595214844 Grad time: 1.0452032089233398
2019-12-29 19:27:29: Embed time: 0.0009975433349609375
2019-12-29 19:27:29: Train loss: -103350.44947712781
2019-12-29 19:27:30: Loss time: 0.4966714382171631 Grad time: 1.0322389602661133
2019-12-29 19:27:30: Embed time: 0.0009980201721191406
2019-12-29 19:27:31: Train loss: -103351.88557201052
2019-12-29 19:27:32: Loss time: 0.504650354385376 Grad time: 1.1070377826690674
2019-12-29 19:27:32: Embed time: 0.000997304916381836
2019-12-29 19:27:32: Train loss: -103353.3207779726
2019-12-29 19:27:33: Loss time: 0.5056467056274414 Grad time: 0.9484612941741943
2019-12-29 19:27:33: Embed time: 0.0009965896606445312
2019-12-29 19:27:34: Train loss: -103354.75501750747
2019-12-29 19:27:35: Loss time: 0.5026540756225586 Grad time: 1.0182788372039795
2019-12-29 19:27:35: Embed time: 0.000997304916381836
2019-12-29 19:27:36: Train loss: -103356.18822421931
2019-12-29 19:27:37: Loss time: 0.5794486999511719 Grad time: 1.0571725368499756
2019-12-29 19:27:37: Embed time: 0.000997304916381836
2019-12-29 19:27:37: Train loss: -103357.62031671766
2019-12-29 19:27:38: Loss time: 0.5106620788574219 Grad time: 0.9763591289520264
2019-12-29 19:27:38: Embed time: 0.0
2019-12-29 19:27:39: Train loss: -103359.05120301219
2019-12-29 19:27:40: Loss time: 0.5295829772949219 Grad time: 1.0541796684265137
2019-12-29 19:27:40: Embed time: 0.0009975433349609375
2019-12-29 19:27:40: Train loss: -103360.48076505962
2019-12-29 19:27:41: Loss time: 0.5235986709594727 Grad time: 1.1060402393341064
2019-12-29 19:27:41: Embed time: 0.0009968280792236328
2019-12-29 19:27:42: Train loss: -103361.90886638063
2019-12-29 19:27:43: Loss time: 0.4996633529663086 Grad time: 1.0681416988372803
2019-12-29 19:27:44: Validation loss: 1.0 Train loss: -103361.90886638063
2019-12-29 19:27:44: Best model so far (label loss):  1.0 at time 10
2019-12-29 19:27:44: Best model stored at output/models/2019-12-29_19_24_52-TRAIN-LR0_001-MB640.model
2019-12-29 19:27:44: Minibatches processed: 100
2019-12-29 19:27:44: Embed time: 0.0
2019-12-29 19:27:45: Train loss: -103363.33533658822
2019-12-29 19:27:46: Loss time: 0.43982982635498047 Grad time: 1.0002961158752441
2019-12-29 19:27:46: Embed time: 0.000997304916381836
2019-12-29 19:27:46: Train loss: -103364.75998588178
2019-12-29 19:27:47: Loss time: 0.5624966621398926 Grad time: 1.0751228332519531
2019-12-29 19:27:47: Embed time: 0.0009970664978027344
2019-12-29 19:27:48: Train loss: -103366.18260295175
2019-12-29 19:27:49: Loss time: 0.5505266189575195 Grad time: 0.9325051307678223
2019-12-29 19:27:49: Embed time: 0.0009975433349609375
2019-12-29 19:27:49: Train loss: -103367.60296123456
2019-12-29 19:27:50: Loss time: 0.5455396175384521 Grad time: 0.9344997406005859
2019-12-29 19:27:50: Embed time: 0.000997304916381836
2019-12-29 19:27:51: Train loss: -103369.02082549814
2019-12-29 19:27:52: Loss time: 0.5155947208404541 Grad time: 1.1279823780059814
2019-12-29 19:27:52: Embed time: 0.0009980201721191406
2019-12-29 19:27:52: Train loss: -103370.435949749
2019-12-29 19:27:54: Loss time: 0.5146224498748779 Grad time: 1.1180071830749512
2019-12-29 19:27:54: Embed time: 0.000997781753540039
2019-12-29 19:27:54: Train loss: -103371.8480875064
2019-12-29 19:27:55: Loss time: 0.5166440010070801 Grad time: 1.1110007762908936
2019-12-29 19:27:55: Embed time: 0.0
2019-12-29 19:27:56: Train loss: -103373.25700424437
2019-12-29 19:27:57: Loss time: 0.540553092956543 Grad time: 1.1559081077575684
2019-12-29 19:27:57: Embed time: 0.0
2019-12-29 19:27:57: Train loss: -103374.6624700828
2019-12-29 19:27:58: Loss time: 0.5275897979736328 Grad time: 0.9743926525115967
2019-12-29 19:27:58: Embed time: 0.000997781753540039
2019-12-29 19:27:59: Train loss: -103376.06427287325
2019-12-29 19:28:00: Loss time: 0.5196099281311035 Grad time: 1.065147876739502
2019-12-29 19:28:01: Validation loss: 1.0 Train loss: -103376.06427287325
2019-12-29 19:28:01: Best model so far (label loss):  1.0 at time 10
2019-12-29 19:28:01: Best model stored at output/models/2019-12-29_19_24_52-TRAIN-LR0_001-MB640.model
2019-12-29 19:28:01: Minibatches processed: 110
